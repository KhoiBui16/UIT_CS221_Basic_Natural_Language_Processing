{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69298874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải tokenizer...\n",
      "Đang tokenize toàn bộ dữ liệu...\n",
      "Đang tạo Dataset từ dữ liệu đã tokenize...\n",
      "Đang tạo DataCollator...\n",
      "Đang tạo DataLoader...\n",
      "\n",
      "--- BẮT ĐẦU LẤY BATCH ĐẦU TIÊN ---\n",
      "✅✅✅ THÀNH CÔNG! Đã lấy được batch đầu tiên mà không có lỗi.\n",
      "Kích thước input_ids: torch.Size([2, 93])\n"
     ]
    }
   ],
   "source": [
    "# === BẮT ĐẦU ĐOẠN CODE KIỂM TRA MỚI (ROBUST HƠN) ===\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "# 1. TẠO DỮ LIỆU GIẢ LẬP (KHÔNG THAY ĐỔI)\n",
    "data = {\n",
    "    \"prompt\": [\n",
    "        \"Vào những năm 1960, nơi nào trở thành trung tâm của thế hệ âm nhạc beat và folk?\",\n",
    "        \"Tác phẩm điêu khắc nổi tiếng nào nằm ở lối vào công viên?\",\n",
    "    ],\n",
    "    \"context\": [\n",
    "        \"Những năm 1960 khu này trở thành một trong những trung tâm của thế hệ âm nhạc beat và folk (dân gian), khi Allen Ginsberg và Bob Dylan sinh sống tại đó.\",\n",
    "        \"Công viên có một cái hồ lớn ở trung tâm. Ở lối vào phía nam là một bức tượng ngựa bằng đồng.\",\n",
    "    ],\n",
    "    \"response\": [\n",
    "        \"Quảng trường Washington là trung tâm của thế hệ âm nhạc beat và folk vào những năm 1960.\",\n",
    "        \"Một bức tượng sư tử bằng đá cẩm thạch được đặt ở lối vào công viên.\",\n",
    "    ],\n",
    "    \"label\": [\"no\", \"intrinsic\"],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. CẤU HÌNH TỐI GIẢN (KHÔNG THAY ĐỔI)\n",
    "MODEL_NAME = \"MoritzLaurer/ernie-m-large-mnli-xnli\"\n",
    "MAX_LENGTH = 512\n",
    "LABEL_MAP = {\"intrinsic\": 0, \"extrinsic\": 1, \"no\": 2}\n",
    "\n",
    "# 3. CHUẨN BỊ DỮ LIỆU (KHÔNG THAY ĐỔI)\n",
    "premise = (\n",
    "    \"Câu hỏi: \" + df[\"prompt\"].astype(str) + \" Ngữ cảnh: \" + df[\"context\"].astype(str)\n",
    ")\n",
    "hypothesis = df[\"response\"].astype(str)\n",
    "df[\"input_text\"] = premise + \" </s></s> \" + hypothesis\n",
    "df[\"label_id\"] = df[\"label\"].map(LABEL_MAP)\n",
    "\n",
    "# ( # <-- SỬA ĐỔI 1 ) Tải tokenizer TRƯỚC\n",
    "print(\"Đang tải tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# ( # <-- SỬA ĐỔI 2 ) Tokenize TOÀN BỘ dữ liệu cùng một lúc\n",
    "print(\"Đang tokenize toàn bộ dữ liệu...\")\n",
    "# Chuyển cột input_text thành một danh sách các câu\n",
    "list_of_texts = df[\"input_text\"].to_list()\n",
    "# Gọi tokenizer trên cả danh sách\n",
    "encodings = tokenizer(\n",
    "    list_of_texts,\n",
    "    max_length=MAX_LENGTH,\n",
    "    truncation=True,\n",
    "    padding=False,  # Quan trọng: Không padding ở bước này\n",
    ")\n",
    "\n",
    "\n",
    "# ( # <-- SỬA ĐỔI 3 ) CLASS DATASET MỚI (ĐƠN GIẢN HƠN)\n",
    "# Nhiệm vụ của nó bây giờ chỉ là lấy ra các item đã được xử lý sẵn\n",
    "class PreTokenizedDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Lấy tất cả các encoding cho item thứ idx\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        # Thêm nhãn vào\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "\n",
    "# 5. TẠO PIPELINE (với Dataset mới)\n",
    "try:\n",
    "    print(\"Đang tạo Dataset từ dữ liệu đã tokenize...\")\n",
    "    labels = df[\"label_id\"].to_list()\n",
    "    dataset = PreTokenizedDataset(encodings=encodings, labels=labels)\n",
    "\n",
    "    print(\"Đang tạo DataCollator...\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    print(\"Đang tạo DataLoader...\")\n",
    "    loader = DataLoader(dataset, batch_size=2, collate_fn=data_collator)\n",
    "\n",
    "    print(\"\\n--- BẮT ĐẦU LẤY BATCH ĐẦU TIÊN ---\")\n",
    "    sample_batch = next(iter(loader))\n",
    "    print(\"✅✅✅ THÀNH CÔNG! Đã lấy được batch đầu tiên mà không có lỗi.\")\n",
    "    print(\"Kích thước input_ids:\", sample_batch[\"input_ids\"].shape)\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "\n",
    "    print(f\"\\n❌❌❌ THẤT BẠI! Vẫn xảy ra lỗi.\")\n",
    "    print(f\"Loại lỗi: {type(e).__name__}\")\n",
    "    print(f\"Thông điệp lỗi: {e}\")\n",
    "    # In traceback để xem chi tiết hơn\n",
    "    traceback.print_exc()\n",
    "\n",
    "# === KẾT THÚC ĐOẠN CODE KIỂM TRA ===\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
