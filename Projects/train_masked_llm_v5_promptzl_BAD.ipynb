{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c761c320",
   "metadata": {},
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f24b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [1] - ƒê√É C·∫¨P NH·∫¨T\n",
    "import os\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    \"joeddav/xlm-roberta-large-xnli\",\n",
    "    \"microsoft/infoxlm-large\",\n",
    "    \"uitnlp/CafeBERT\",\n",
    "    \"FacebookAI/xlm-roberta-large\",\n",
    "    \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\",\n",
    "    \"MoritzLaurer/ernie-m-large-mnli-xnli\",\n",
    "    \"microsoft/deberta-xlarge-mnli\",\n",
    "]\n",
    "\n",
    "\n",
    "class Config:\n",
    "    ROOT_DIR = os.getcwd()\n",
    "    DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "    # --- THAY ƒê·ªîI QUAN TR·ªåNG ---\n",
    "    # Tr·ªè ƒë·∫øn file ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω b·∫±ng semantic search\n",
    "    TRAIN_FILE = os.path.join(DATA_DIR, \"vihallu-train.csv\")\n",
    "\n",
    "    TEST_FILE = os.path.join(DATA_DIR, \"vihallu-public-test.csv\")\n",
    "    SUBMISSION_DIR = os.path.join(ROOT_DIR, \"submission\")\n",
    "    SUBMISSION_CSV = \"submit.csv\"\n",
    "    SUBMISSION_ZIP = \"submit.zip\"\n",
    "\n",
    "    MODEL_NAME = MODEL_NAMES[2]\n",
    "    MODEL_OUTPUT_DIR = os.path.join(\n",
    "        ROOT_DIR, \"models\", f\"{MODEL_NAME.split('/')[-1]}-tuned\"\n",
    "    )\n",
    "\n",
    "    MAX_LENGTH = 512\n",
    "    RANDOM_STATE = 42\n",
    "    EPOCHS = 10\n",
    "    BATCH_SIZE = 1\n",
    "    GRADIENT_ACCUMULATION_STEPS = 16\n",
    "    SCHEDULER_TYPE = \"cosine\"\n",
    "    LEARNING_RATE = 8e-6  # Gi·∫£m LR m·ªôt ch√∫t cho PET\n",
    "    WEIGHT_DECAY = 0.02\n",
    "    CLASSIFIER_DROPOUT = 0.05\n",
    "    EPSILON = 1e-8\n",
    "    PATIENCE_LIMIT = 2\n",
    "    TOTAL_STEP_SCALE = 0.1\n",
    "    LABEL_SMOOTHING = 0.05\n",
    "    VALIDATION_SPLIT_SIZE = 0.2\n",
    "\n",
    "    # Gi·ªØ nguy√™n mapping ƒë·ªÉ ƒë·ªçc d·ªØ li·ªáu, nh∆∞ng s·∫Ω ƒë∆∞·ª£c √°nh x·∫° l·∫°i trong PET\n",
    "    LABEL_MAP = {\"intrinsic\": 0, \"extrinsic\": 1, \"no\": 2}\n",
    "    ID2LABEL = {v: k for k, v in LABEL_MAP.items()}\n",
    "    CLASS_WEIGHTS = [1.0393466963622866, 1.0114145354717525, 0.9531590413943355]\n",
    "\n",
    "\n",
    "cfg = Config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01017e0",
   "metadata": {},
   "source": [
    "# LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1e41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Th∆∞ m·ª•c g·ªëc ƒë·ªÉ l∆∞u t·∫•t c·∫£ c√°c file log\n",
    "LOG_BASE_DIR = \"logs\"\n",
    "\n",
    "# D√πng m·ªôt dictionary ƒë·ªÉ l∆∞u c√°c logger ƒë√£ t·∫°o, tr√°nh vi·ªác t·∫°o l·∫°i v√† g√¢y ra log tr√πng l·∫∑p\n",
    "_loggers = {}\n",
    "\n",
    "\n",
    "def setup_logger(model_name: str, log_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Thi·∫øt l·∫≠p v√† tr·∫£ v·ªÅ m·ªôt logger ƒë·ªÉ ghi log v√†o c·∫£ console v√† file.\n",
    "\n",
    "    - M·ªói model s·∫Ω c√≥ m·ªôt th∆∞ m·ª•c log ri√™ng d·ª±a tr√™n `model_name`.\n",
    "    - M·ªói l·∫ßn ch·∫°y s·∫Ω t·∫°o m·ªôt file log m·ªõi c√≥ t√™n l√† timestamp (v√≠ d·ª•: 2023-10-27_15-30-00.log).\n",
    "    - ƒê·∫£m b·∫£o kh√¥ng c√≥ log n√†o b·ªã ghi ƒë√®.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): T√™n c·ªßa model, d√πng ƒë·ªÉ t·∫°o th∆∞ m·ª•c con. V√≠ d·ª•: 'xnli-large-tuned'.\n",
    "        log_level (int): C·∫•p ƒë·ªô log, m·∫∑c ƒë·ªãnh l√† logging.INFO.\n",
    "\n",
    "    Returns:\n",
    "        logging.Logger: Instance c·ªßa logger ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh.\n",
    "    \"\"\"\n",
    "    # N·∫øu logger cho model n√†y ƒë√£ t·ªìn t·∫°i, tr·∫£ v·ªÅ n√≥ ngay l·∫≠p t·ª©c\n",
    "    if model_name in _loggers:\n",
    "        return _loggers[model_name]\n",
    "\n",
    "    # X·ª≠ l√Ω t√™n model ƒë·ªÉ an to√†n khi t·∫°o t√™n th∆∞ m·ª•c (thay th·∫ø \"/\")\n",
    "    safe_model_name = model_name.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    model_log_dir = os.path.join(LOG_BASE_DIR, safe_model_name)\n",
    "    os.makedirs(model_log_dir, exist_ok=True)\n",
    "\n",
    "    # T·∫°o logger\n",
    "    logger = logging.getLogger(safe_model_name)\n",
    "    logger.setLevel(log_level)\n",
    "\n",
    "    # NgƒÉn kh√¥ng cho log lan truy·ªÅn ƒë·∫øn root logger ƒë·ªÉ tr√°nh in ra console 2 l·∫ßn\n",
    "    logger.propagate = False\n",
    "\n",
    "    # ƒê·ªãnh d·∫°ng cho log message\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - [%(levelname)s] - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "\n",
    "    # T·∫°o File Handler ƒë·ªÉ ghi log ra file\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    log_file_path = os.path.join(model_log_dir, f\"{timestamp}.log\")\n",
    "\n",
    "    file_handler = logging.FileHandler(log_file_path, encoding=\"utf-8\")\n",
    "    file_handler.setLevel(log_level)\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    # T·∫°o Console (Stream) Handler ƒë·ªÉ in log ra m√†n h√¨nh\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(log_level)\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    # Th√™m c√°c handler v√†o logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    # L∆∞u logger v√†o cache\n",
    "    _loggers[model_name] = logger\n",
    "\n",
    "    logger.info(\n",
    "        f\"Logger cho '{safe_model_name}' ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o. File log: {log_file_path}\"\n",
    "    )\n",
    "\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148d0474",
   "metadata": {},
   "source": [
    "## Setup logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16eac9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:44:15 - [INFO] - Logger cho 'uitnlp_CafeBERT-training' ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o. File log: logs/uitnlp_CafeBERT-training/2025-10-16_21-44-15.log\n",
      "2025-10-16 21:44:15 - [INFO] - Logger initialized for uitnlp/CafeBERT\n",
      "2025-10-16 21:44:15 - [INFO] - ============================================================\n",
      "2025-10-16 21:44:15 - [INFO] - üöÄ STARTING TRAINING SESSION\n",
      "2025-10-16 21:44:15 - [INFO] - ============================================================\n",
      "2025-10-16 21:44:15 - [INFO] - ROOT_DIR: /home/guest/Projects/CS221\n",
      "2025-10-16 21:44:15 - [INFO] - DATA_DIR: /home/guest/Projects/CS221/data\n",
      "2025-10-16 21:44:15 - [INFO] - TRAIN_FILE: /home/guest/Projects/CS221/data/vihallu-train.csv\n",
      "2025-10-16 21:44:15 - [INFO] - TEST_FILE: /home/guest/Projects/CS221/data/vihallu-public-test.csv\n",
      "2025-10-16 21:44:15 - [INFO] - SUBMISSION_DIR: /home/guest/Projects/CS221/submission\n",
      "2025-10-16 21:44:15 - [INFO] - SUBMISSION_CSV: submit.csv\n",
      "2025-10-16 21:44:15 - [INFO] - SUBMISSION_ZIP: submit.zip\n",
      "2025-10-16 21:44:15 - [INFO] - MODEL_NAME: uitnlp/CafeBERT\n",
      "2025-10-16 21:44:15 - [INFO] - MODEL_OUTPUT_DIR: /home/guest/Projects/CS221/models/CafeBERT-tuned\n",
      "2025-10-16 21:44:15 - [INFO] - MAX_LENGTH: 512\n",
      "2025-10-16 21:44:15 - [INFO] - RANDOM_STATE: 42\n",
      "2025-10-16 21:44:15 - [INFO] - EPOCHS: 10\n",
      "2025-10-16 21:44:15 - [INFO] - BATCH_SIZE: 1\n",
      "2025-10-16 21:44:15 - [INFO] - GRADIENT_ACCUMULATION_STEPS: 16\n",
      "2025-10-16 21:44:15 - [INFO] - SCHEDULER_TYPE: cosine\n",
      "2025-10-16 21:44:15 - [INFO] - LEARNING_RATE: 8e-06\n",
      "2025-10-16 21:44:15 - [INFO] - WEIGHT_DECAY: 0.02\n",
      "2025-10-16 21:44:15 - [INFO] - CLASSIFIER_DROPOUT: 0.05\n",
      "2025-10-16 21:44:15 - [INFO] - EPSILON: 1e-08\n",
      "2025-10-16 21:44:15 - [INFO] - PATIENCE_LIMIT: 2\n",
      "2025-10-16 21:44:15 - [INFO] - TOTAL_STEP_SCALE: 0.1\n",
      "2025-10-16 21:44:15 - [INFO] - LABEL_SMOOTHING: 0.05\n",
      "2025-10-16 21:44:15 - [INFO] - VALIDATION_SPLIT_SIZE: 0.2\n",
      "2025-10-16 21:44:15 - [INFO] - LABEL_MAP: {'intrinsic': 0, 'extrinsic': 1, 'no': 2}\n",
      "2025-10-16 21:44:15 - [INFO] - ID2LABEL: {0: 'intrinsic', 1: 'extrinsic', 2: 'no'}\n",
      "2025-10-16 21:44:15 - [INFO] - CLASS_WEIGHTS: [1.0393466963622866, 1.0114145354717525, 0.9531590413943355]\n",
      "2025-10-16 21:44:15 - [INFO] - ============================================================\n",
      "2025-10-16 21:44:15 - [INFO] - Logger initialized for uitnlp/CafeBERT\n",
      "2025-10-16 21:44:15 - [INFO] - ============================================================\n",
      "2025-10-16 21:44:15 - [INFO] - üöÄ STARTING TRAINING SESSION\n",
      "2025-10-16 21:44:15 - [INFO] - ============================================================\n",
      "2025-10-16 21:44:15 - [INFO] - ROOT_DIR: /home/guest/Projects/CS221\n",
      "2025-10-16 21:44:15 - [INFO] - DATA_DIR: /home/guest/Projects/CS221/data\n",
      "2025-10-16 21:44:15 - [INFO] - TRAIN_FILE: /home/guest/Projects/CS221/data/vihallu-train.csv\n",
      "2025-10-16 21:44:15 - [INFO] - TEST_FILE: /home/guest/Projects/CS221/data/vihallu-public-test.csv\n",
      "2025-10-16 21:44:15 - [INFO] - SUBMISSION_DIR: /home/guest/Projects/CS221/submission\n",
      "2025-10-16 21:44:15 - [INFO] - SUBMISSION_CSV: submit.csv\n",
      "2025-10-16 21:44:15 - [INFO] - SUBMISSION_ZIP: submit.zip\n",
      "2025-10-16 21:44:15 - [INFO] - MODEL_NAME: uitnlp/CafeBERT\n",
      "2025-10-16 21:44:15 - [INFO] - MODEL_OUTPUT_DIR: /home/guest/Projects/CS221/models/CafeBERT-tuned\n",
      "2025-10-16 21:44:15 - [INFO] - MAX_LENGTH: 512\n",
      "2025-10-16 21:44:15 - [INFO] - RANDOM_STATE: 42\n",
      "2025-10-16 21:44:15 - [INFO] - EPOCHS: 10\n",
      "2025-10-16 21:44:15 - [INFO] - BATCH_SIZE: 1\n",
      "2025-10-16 21:44:15 - [INFO] - GRADIENT_ACCUMULATION_STEPS: 16\n",
      "2025-10-16 21:44:15 - [INFO] - SCHEDULER_TYPE: cosine\n",
      "2025-10-16 21:44:15 - [INFO] - LEARNING_RATE: 8e-06\n",
      "2025-10-16 21:44:15 - [INFO] - WEIGHT_DECAY: 0.02\n",
      "2025-10-16 21:44:15 - [INFO] - CLASSIFIER_DROPOUT: 0.05\n",
      "2025-10-16 21:44:15 - [INFO] - EPSILON: 1e-08\n",
      "2025-10-16 21:44:15 - [INFO] - PATIENCE_LIMIT: 2\n",
      "2025-10-16 21:44:15 - [INFO] - TOTAL_STEP_SCALE: 0.1\n",
      "2025-10-16 21:44:15 - [INFO] - LABEL_SMOOTHING: 0.05\n",
      "2025-10-16 21:44:15 - [INFO] - VALIDATION_SPLIT_SIZE: 0.2\n",
      "2025-10-16 21:44:15 - [INFO] - LABEL_MAP: {'intrinsic': 0, 'extrinsic': 1, 'no': 2}\n",
      "2025-10-16 21:44:15 - [INFO] - ID2LABEL: {0: 'intrinsic', 1: 'extrinsic', 2: 'no'}\n",
      "2025-10-16 21:44:15 - [INFO] - CLASS_WEIGHTS: [1.0393466963622866, 1.0114145354717525, 0.9531590413943355]\n",
      "2025-10-16 21:44:15 - [INFO] - ============================================================\n"
     ]
    }
   ],
   "source": [
    "logger = setup_logger(f\"{cfg.MODEL_NAME}-training\")\n",
    "logger.info(f\"Logger initialized for {cfg.MODEL_NAME}\")\n",
    "\n",
    "logger.info(\"=\" * 60)\n",
    "logger.info(\"üöÄ STARTING TRAINING SESSION\")\n",
    "logger.info(\"=\" * 60)\n",
    "for key, value in Config.__dict__.items():\n",
    "    if not key.startswith(\"__\") and not callable(value):\n",
    "        logger.info(f\"{key}: {value}\")\n",
    "logger.info(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbc1878",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfa808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def prepare_data(config, logger=None):\n",
    "    df = pd.read_csv(config.TRAIN_FILE)\n",
    "    print(f\"‚úÖ ƒê·ªçc th√†nh c√¥ng {len(df)} m·∫´u t·ª´ file ƒë√£ x·ª≠ l√Ω: {config.TRAIN_FILE}\")\n",
    "\n",
    "    # T·∫°o 2 c·ªôt premise v√† hypothesis t·ª´ ng·ªØ c·∫£nh (context)\n",
    "    df[\"premise\"] = (\n",
    "        \"C√¢u h·ªèi: \"\n",
    "        + df[\"prompt\"].astype(str)\n",
    "        + \" Ng·ªØ c·∫£nh: \"\n",
    "        + df[\"context\"].astype(str)\n",
    "    )\n",
    "    df[\"hypothesis\"] = df[\"response\"].astype(str)\n",
    "\n",
    "    df[\"label_id\"] = df[\"label\"].map(config.LABEL_MAP)\n",
    "    df.dropna(subset=[\"label_id\"], inplace=True)\n",
    "    df[\"label_id\"] = df[\"label_id\"].astype(int)\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        df,\n",
    "        test_size=config.VALIDATION_SPLIT_SIZE,\n",
    "        random_state=config.RANDOM_STATE,\n",
    "        stratify=df[\"label_id\"],\n",
    "    )\n",
    "\n",
    "    if logger:\n",
    "        logger.info(\n",
    "            f\"Chia d·ªØ li·ªáu: {len(train_df)} m·∫´u train, {len(val_df)} m·∫´u validation.\"\n",
    "        )\n",
    "\n",
    "    # --- PH·∫¶N N√ÇNG C·∫§P: L∆ØU FILE RA TH∆Ø M·ª§C DATA ---\n",
    "    # T·∫°o th∆∞ m·ª•c 'processed' trong 'data' n·∫øu ch∆∞a c√≥\n",
    "    processed_data_dir = os.path.join(config.DATA_DIR, \"processed\")\n",
    "    os.makedirs(processed_data_dir, exist_ok=True)\n",
    "\n",
    "    # ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n file\n",
    "    train_output_path = os.path.join(processed_data_dir, \"train_split.csv\")\n",
    "    val_output_path = os.path.join(processed_data_dir, \"validation_split.csv\")\n",
    "\n",
    "    # L∆∞u c√°c DataFrame\n",
    "    train_df.to_csv(train_output_path, index=False, encoding=\"utf-8-sig\")\n",
    "    val_df.to_csv(val_output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u t·∫≠p train v√†o: {train_output_path}\")\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u t·∫≠p validation v√†o: {val_output_path}\")\n",
    "    # --- K·∫æT TH√öC PH·∫¶N N√ÇNG C·∫§P ---\n",
    "\n",
    "    return train_df, val_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3844963",
   "metadata": {},
   "source": [
    "# Model (C·∫≠p nh·∫≠t cho Masked Language Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e80ebeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForMaskedLM,\n",
    ")  # <-- THAY ƒê·ªîI ·ªû ƒê√ÇY\n",
    "\n",
    "\n",
    "def get_model_and_tokenizer(config):\n",
    "    \"\"\"T·∫£i pre-trained model v√† tokenizer cho Masked LM.\"\"\"\n",
    "    print(f\"ƒêang t·∫£i model: {config.MODEL_NAME}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
    "\n",
    "    cfg_model = AutoConfig.from_pretrained(config.MODEL_NAME, trust_remote_code=True)\n",
    "    print(f\"Model config: {cfg_model}\")\n",
    "\n",
    "    # --- THAY ƒê·ªîI QUAN TR·ªåNG ---\n",
    "    # Chuy·ªÉn t·ª´ SequenceClassification sang MaskedLM\n",
    "    model = AutoModelForMaskedLM.from_pretrained(\n",
    "        config.MODEL_NAME,\n",
    "        config=cfg_model,\n",
    "    )\n",
    "    # -------------------------\n",
    "\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aed701",
   "metadata": {},
   "source": [
    "# Thi·∫øt l·∫≠p Pattern & Verbalizer cho PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8723a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def setup_pet_components(tokenizer, logger):\n",
    "    \"\"\"\n",
    "    ƒê·ªãnh nghƒ©a Pattern v√† Verbalizer cho ph∆∞∆°ng ph√°p PET.\n",
    "    \"\"\"\n",
    "    # 1. ƒê·ªãnh nghƒ©a Pattern (M·∫´u c√¢u)\n",
    "    # --- THAY ƒê·ªîI QUAN TR·ªåNG: ƒê∆∞a {mask} l√™n ƒë·∫ßu ---\n",
    "    pattern = '{mask}! D·ª±a tr√™n th√¥ng tin: \"{premise}\", c√¢u tr·∫£ l·ªùi \"{hypothesis}\" c√≥ ƒë√∫ng kh√¥ng?'\n",
    "    # B·∫°n c≈©ng c√≥ th·ªÉ th·ª≠ c√°c pattern kh√°c nh∆∞:\n",
    "    # pattern = \"Ph√°n quy·∫øt: {mask}. B·∫±ng ch·ª©ng: \\\"{premise}\\\". Gi·∫£ thuy·∫øt: \\\"{hypothesis}\\\".\"\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    logger.info(f\"S·ª≠ d·ª•ng Pattern (ƒë√£ s·ª≠a l·ªói): {pattern}\")\n",
    "\n",
    "    # 2. ƒê·ªãnh nghƒ©a Verbalizer (Gi·ªØ nguy√™n)\n",
    "    verbalizer = {\n",
    "        2: \"chu·∫©n\",  # no Thay \"ƒë√∫ng\" b·∫±ng \"chu·∫©n\" ho·∫∑c \"ch√≠nh x√°c\"\n",
    "        0: \"tr·∫≠t\",  # intrinsic\n",
    "        1: \"kh√°c\",  # extrinsic\n",
    "    }\n",
    "    logger.info(f\"S·ª≠ d·ª•ng Verbalizer: {verbalizer}\")\n",
    "\n",
    "    # 3. L·∫•y token ID cho c√°c t·ª´ trong verbalizer\n",
    "    verbalizer_token_ids = {\n",
    "        label_id: tokenizer.convert_tokens_to_ids(verb)\n",
    "        for label_id, verb in verbalizer.items()\n",
    "    }\n",
    "\n",
    "    # Ki·ªÉm tra xem c√≥ t·ª´ n√†o b·ªã t√°ch th√†nh nhi·ªÅu sub-token kh√¥ng\n",
    "    for label_id, verb in verbalizer.items():\n",
    "        tokens = tokenizer.tokenize(verb)\n",
    "        if len(tokens) > 1:\n",
    "            logger.warning(f\"‚ö†Ô∏è T·ª´ '{verb}' b·ªã t√°ch th√†nh nhi·ªÅu token: {tokens}.\")\n",
    "        else:\n",
    "            logger.info(\n",
    "                f\"‚úÖ T·ª´ '{verb}' (ID: {verbalizer_token_ids[label_id]}) l√† token ƒë∆°n l·∫ª.\"\n",
    "            )\n",
    "\n",
    "    return pattern, verbalizer, verbalizer_token_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3b202",
   "metadata": {},
   "source": [
    "# Hallucination Dataset (C·∫≠p nh·∫≠t cho PET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce606de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class HallucinationDataset(Dataset):\n",
    "    def __init__(self, premises, hypotheses, labels, tokenizer, max_len, pattern):\n",
    "        self.premises = premises\n",
    "        self.hypotheses = hypotheses\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pattern = pattern\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        premise = self.premises[idx]\n",
    "        hypothesis = self.hypotheses[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 1. T·∫°o c√¢u prompt ho√†n ch·ªânh b·∫±ng c√°ch ƒëi·ªÅn premise v√† hypothesis v√†o pattern\n",
    "        prompt_text = self.pattern.format(\n",
    "            premise=premise, hypothesis=hypothesis, mask=self.tokenizer.mask_token\n",
    "        )\n",
    "\n",
    "        # 2. Tokenize c√¢u prompt ƒë√£ t·∫°o\n",
    "        encoding = self.tokenizer(\n",
    "            prompt_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=False,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"],\n",
    "            \"attention_mask\": encoding[\"attention_mask\"],\n",
    "            \"labels\": label,  # Tr·∫£ v·ªÅ s·ªë nguy√™n ƒë·ªÉ DataCollator x·ª≠ l√Ω\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21114019",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b10adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim import AdamW\n",
    "from huggingface_hub import login\n",
    "from transformers import get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.contrib.logging import logging_redirect_tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09e6336",
   "metadata": {},
   "source": [
    "## Train & Evaluate Functions (C·∫≠p nh·∫≠t cho PET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1154314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    verbalizer_ids_tensor,\n",
    "    label_map,\n",
    "    epoch=None,\n",
    "    total_epochs=None,\n",
    "    gradient_accumulation_steps=1,\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    desc = f\"Train\" if epoch is None else f\"Epoch {epoch}/{total_epochs}\"\n",
    "    progress_bar = tqdm(\n",
    "        data_loader, desc=desc, leave=False, dynamic_ncols=True, mininterval=0.5\n",
    "    )\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    steps_in_epoch = len(data_loader)\n",
    "    with logging_redirect_tqdm():\n",
    "        for step, batch in enumerate(progress_bar):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            original_labels = batch[\"labels\"]\n",
    "            target_labels = torch.tensor(\n",
    "                [label_map[l.item()] for l in original_labels], dtype=torch.long\n",
    "            ).to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            mask_token_indices = (input_ids == tokenizer.mask_token_id).nonzero(\n",
    "                as_tuple=True\n",
    "            )[1]\n",
    "            mask_logits = logits[torch.arange(logits.size(0)), mask_token_indices]\n",
    "            verbalizer_logits = mask_logits[:, verbalizer_ids_tensor]\n",
    "\n",
    "            loss = loss_fn(verbalizer_logits, target_labels)\n",
    "            total_loss += loss.item()\n",
    "            scaled_loss = loss / gradient_accumulation_steps\n",
    "            scaled_loss.backward()\n",
    "\n",
    "            if (step + 1) % gradient_accumulation_steps == 0 or (\n",
    "                step + 1\n",
    "            ) == steps_in_epoch:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3398cf",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "194e5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model,\n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    tokenizer,\n",
    "    verbalizer_ids_tensor,\n",
    "    label_map,\n",
    "    id2label_map,\n",
    "):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_val_loss = 0\n",
    "    progress_bar = tqdm(data_loader, desc=\"Evaluating\", leave=False, dynamic_ncols=True)\n",
    "\n",
    "    with torch.no_grad(), logging_redirect_tqdm():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            original_labels = batch[\"labels\"]\n",
    "            target_labels = torch.tensor(\n",
    "                [label_map[l.item()] for l in original_labels], dtype=torch.long\n",
    "            ).to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            mask_token_indices = (input_ids == tokenizer.mask_token_id).nonzero(\n",
    "                as_tuple=True\n",
    "            )[1]\n",
    "            mask_logits = logits[torch.arange(logits.size(0)), mask_token_indices]\n",
    "            verbalizer_logits = mask_logits[:, verbalizer_ids_tensor]\n",
    "\n",
    "            loss = loss_fn(verbalizer_logits, target_labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            preds_indices = torch.argmax(verbalizer_logits, dim=-1)\n",
    "            original_preds = [id2label_map[p.item()] for p in preds_indices]\n",
    "\n",
    "            all_preds.extend(original_preds)\n",
    "            all_labels.extend(original_labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(data_loader)\n",
    "    return all_labels, all_preds, avg_val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08cfc13",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a07ea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dotenv_path: /home/guest/Projects/CS221/envs/.env\n"
     ]
    }
   ],
   "source": [
    "# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file envs/.env.\n",
    "dotenv_path = os.path.join(os.getcwd(), \"envs\", \".env\")\n",
    "load_dotenv(dotenv_path)\n",
    "print(f\"dotenv_path: {dotenv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c48a9b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: T√¨m th·∫•y HUGGING_FACE_TOKEN. ƒêang ƒëƒÉng nh·∫≠p...\n",
      "INFO: ƒêƒÉng nh·∫≠p Hugging Face th√†nh c√¥ng.\n"
     ]
    }
   ],
   "source": [
    "# l·∫•y HF token ƒë·ªÉ login\n",
    "hf_token = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "\n",
    "if hf_token:\n",
    "    print(\"INFO: T√¨m th·∫•y HUGGING_FACE_TOKEN. ƒêang ƒëƒÉng nh·∫≠p...\")\n",
    "    login(token=hf_token)\n",
    "    print(\"INFO: ƒêƒÉng nh·∫≠p Hugging Face th√†nh c√¥ng.\")\n",
    "else:\n",
    "    print(\n",
    "        \"WARNING: Kh√¥ng t√¨m th·∫•y HUGGING_FACE_TOKEN trong file .env. M·ªôt s·ªë model c√≥ th·ªÉ y√™u c·∫ßu ƒëƒÉng nh·∫≠p.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b94e0",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# 1. Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20c739cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:44:18 - [INFO] - B·∫Øt ƒë·∫ßu pipeline hu·∫•n luy·ªán PET.\n",
      "2025-10-16 21:44:18 - [INFO] - B∆∞·ªõc 1: Chu·∫©n b·ªã d·ªØ li·ªáu...\n",
      "2025-10-16 21:44:18 - [INFO] - Chia d·ªØ li·ªáu: 5600 m·∫´u train, 1400 m·∫´u validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê·ªçc th√†nh c√¥ng 7000 m·∫´u t·ª´ file ƒë√£ x·ª≠ l√Ω: /home/guest/Projects/CS221/data/vihallu-train.csv\n",
      "‚úÖ ƒê√£ l∆∞u t·∫≠p train v√†o: /home/guest/Projects/CS221/data/processed/train_split.csv\n",
      "‚úÖ ƒê√£ l∆∞u t·∫≠p validation v√†o: /home/guest/Projects/CS221/data/processed/validation_split.csv\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"B·∫Øt ƒë·∫ßu pipeline hu·∫•n luy·ªán PET.\")\n",
    "logger.info(\"B∆∞·ªõc 1: Chu·∫©n b·ªã d·ªØ li·ªáu...\")\n",
    "train_df, val_df = prepare_data(cfg, logger=logger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8a1b7",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# 2. T·∫£i model, tokenizer v√† thi·∫øt l·∫≠p PET\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f4f00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:44:18 - [INFO] - B∆∞·ªõc 2: T·∫£i model 'uitnlp/CafeBERT' v√† tokenizer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang t·∫£i model: uitnlp/CafeBERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:44:20 - [INFO] - Thi·∫øt l·∫≠p c√°c th√†nh ph·∫ßn cho PET...\n",
      "2025-10-16 21:44:20 - [INFO] - S·ª≠ d·ª•ng Pattern (ƒë√£ s·ª≠a l·ªói): {mask}! D·ª±a tr√™n th√¥ng tin: \"{premise}\", c√¢u tr·∫£ l·ªùi \"{hypothesis}\" c√≥ ƒë√∫ng kh√¥ng?\n",
      "2025-10-16 21:44:20 - [INFO] - S·ª≠ d·ª•ng Verbalizer: {2: 'chu·∫©n', 0: 'tr·∫≠t', 1: 'kh√°c'}\n",
      "2025-10-16 21:44:20 - [INFO] - ‚úÖ T·ª´ 'chu·∫©n' (ID: 3) l√† token ƒë∆°n l·∫ª.\n",
      "2025-10-16 21:44:20 - [INFO] - ‚úÖ T·ª´ 'tr·∫≠t' (ID: 3) l√† token ƒë∆°n l·∫ª.\n",
      "2025-10-16 21:44:20 - [INFO] - ‚úÖ T·ª´ 'kh√°c' (ID: 3) l√† token ƒë∆°n l·∫ª.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model config: XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"B∆∞·ªõc 2: T·∫£i model '{cfg.MODEL_NAME}' v√† tokenizer...\")\n",
    "model, tokenizer = get_model_and_tokenizer(cfg)\n",
    "\n",
    "logger.info(f\"Thi·∫øt l·∫≠p c√°c th√†nh ph·∫ßn cho PET...\")\n",
    "pattern, verbalizer, verbalizer_token_ids = setup_pet_components(tokenizer, logger)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "verbalizer_ids_tensor = torch.tensor(\n",
    "    [verbalizer_token_ids[i] for i in sorted(verbalizer_token_ids.keys())]\n",
    ").to(device)\n",
    "\n",
    "original_label_to_verbalizer_idx = {\n",
    "    label: i for i, label in enumerate(sorted(verbalizer_token_ids.keys()))\n",
    "}\n",
    "verbalizer_idx_to_original_label = {\n",
    "    i: label for i, label in enumerate(sorted(verbalizer_token_ids.keys()))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ffd869",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# 3. T·∫°o Dataset v√† DataLoader\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9803da5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:44:21 - [INFO] - B∆∞·ªõc 3: T·∫°o Dataset v√† DataLoader...\n",
      "2025-10-16 21:44:21 - [INFO] - ‚úÖ T·∫°o DataLoader th√†nh c√¥ng v·ªõi DataCollatorWithPadding chu·∫©n!\n",
      "2025-10-16 21:44:21 - [INFO] - ‚úÖ T·∫°o DataLoader th√†nh c√¥ng v·ªõi DataCollatorWithPadding chu·∫©n!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "logger.info(\"B∆∞·ªõc 3: T·∫°o Dataset v√† DataLoader...\")\n",
    "train_dataset = HallucinationDataset(\n",
    "    premises=train_df[\"premise\"].to_list(),\n",
    "    hypotheses=train_df[\"hypothesis\"].to_list(),\n",
    "    labels=train_df[\"label_id\"].to_list(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=cfg.MAX_LENGTH,\n",
    "    pattern=pattern,  # <-- Truy·ªÅn pattern v√†o\n",
    ")\n",
    "val_dataset = HallucinationDataset(\n",
    "    premises=val_df[\"premise\"].to_list(),\n",
    "    hypotheses=val_df[\"hypothesis\"].to_list(),\n",
    "    labels=val_df[\"label_id\"].to_list(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=cfg.MAX_LENGTH,\n",
    "    pattern=pattern,  # <-- Truy·ªÅn pattern v√†o\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True, collate_fn=data_collator\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=cfg.BATCH_SIZE, collate_fn=data_collator\n",
    ")\n",
    "logger.info(\"‚úÖ T·∫°o DataLoader th√†nh c√¥ng v·ªõi DataCollatorWithPadding chu·∫©n!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae8a4a1",
   "metadata": {},
   "source": [
    "### Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c8564a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ki·ªÉm tra 1 batch d·ªØ li·ªáu ƒë·∫ßu v√†o ---\n",
      "K√≠ch th∆∞·ªõc input_ids: torch.Size([1, 269])\n",
      "K√≠ch th∆∞·ªõc attention_mask: torch.Size([1, 269])\n",
      "Nh√£n trong batch: tensor([2])\n",
      "\n",
      "M·ªôt m·∫´u ƒë√£ ƒë∆∞·ª£c token h√≥a v√† gi·∫£i m√£ l·∫°i:\n",
      "<s><mask> ! D·ª±a tr√™n th√¥ng tin: \"C√¢u h·ªèi: NƒÉm 2012, t·ªâ tr·ªçng ƒë·∫ßu t∆∞ c·ªßa M·ªπ v√†o R&D l√† 33%, ƒë√∫ng kh√¥ng, v√† ƒëi·ªÅu n√†y cho th·∫•y s·ª± gia tƒÉng v∆∞·ª£t b·∫≠c so v·ªõi c√°c nƒÉm tr∆∞·ªõc ƒë√≥? Ng·ªØ c·∫£nh: D√π gi√° tr·ªã ƒë·∫ßu t∆∞ v√†o R&D t·∫°i M·ªπ cao, n√≥ v·∫´n ch∆∞a ƒë√°p ·ª©ng ƒë∆∞·ª£c m·ª•c ti√™u m√† t·ªïng th·ªëng Obama ƒë·ªÅ ra l√† 3% GDP v√†o th·ªùi ƒëi·ªÉm cu·ªëi nhi·ªám k·ª≥ nƒÉm 2016. S·ª± ƒë·ªôc t√¥n c·ªßa Hoa K·ª≥ trong lƒ©nh v·ª±c n√†y ƒëang b·ªã suy gi·∫£m, th·∫≠m ch√≠ v·ªõi c√°c qu·ªëc gia kh√°c, nh∆∞ Trung Qu·ªëc, ƒëang ƒë·∫©y c√°c ho·∫°t ƒë·ªông t√†i tr·ª£ R&D c·ªßa h·ªçc l√™n m·ª©c ƒë·ªô m·ªõi. T·ª´ nƒÉm 2009 ƒë·∫øn 2012, t·ª∑ tr·ªçng t·ªïng ƒë·∫ßu t∆∞ c·ªßa Hoa K·ª≥ v√†o R&D so v·ªõi th·∫ø gi·ªõi gi·∫£m nh·∫π t·ª´ 30,5% c√≤n 28,1%. M·ªôt v√†i qu·ªëc gia d√†nh t·ªõi h∆°n 4% GDP cho ho·∫°t ƒë·ªông nghi√™n c·ª©u v√† ph√°t tri·ªÉn (Israel, Nh·∫≠t B·∫£n v√† Nam H√†n) v√† c√°c n∆∞·ªõc kh√°c c√≥ k·∫ø ho·∫°ch tƒÉng GERD/GDP t·ªõi 4% nƒÉm 2020 (Ph·∫ßn Lan v√† Thu·ªµ ƒêi·ªÉn).\", c√¢u tr·∫£ l·ªùi \"NƒÉm 2012, t·ª∑ tr·ªçng ƒë·∫ßu t∆∞ c·ªßa M·ªπ v√†o R&D l√† 28,1%, gi·∫£m nh·∫π so v·ªõi m·ª©c 30,5% v√†o nƒÉm 2009, kh√¥ng ph·∫£i l√† 33% nh∆∞ b·∫°n ƒë·ªÅ c·∫≠p.\" c√≥ ƒë√∫ng kh√¥ng?</s>\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Ki·ªÉm tra 1 batch d·ªØ li·ªáu ƒë·∫ßu v√†o ---\")\n",
    "sample_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"K√≠ch th∆∞·ªõc input_ids:\", sample_batch[\"input_ids\"].shape)\n",
    "print(\"K√≠ch th∆∞·ªõc attention_mask:\", sample_batch[\"attention_mask\"].shape)\n",
    "print(\"Nh√£n trong batch:\", sample_batch[\"labels\"])\n",
    "\n",
    "# Gi·∫£i m√£ m·ªôt m·∫´u ƒë·ªÉ xem n√≥ tr√¥ng nh∆∞ th·∫ø n√†o\n",
    "decoded_text = tokenizer.decode(sample_batch[\"input_ids\"][0], skip_special_tokens=False)\n",
    "print(\"\\nM·ªôt m·∫´u ƒë√£ ƒë∆∞·ª£c token h√≥a v√† gi·∫£i m√£ l·∫°i:\")\n",
    "print(decoded_text)\n",
    "print(\"------------------------------------------\\n\")\n",
    "# --- K·∫æT TH√öC B∆Ø·ªöC KI·ªÇM TRA ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fa66f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ki·ªÉm tra chi ti·∫øt 5 m·∫´u ƒë·∫ßu ti√™n ƒë·ªÉ so s√°nh tr∆∞·ªõc v√† sau khi x·ª≠ l√Ω ---\n",
      "\n",
      "=============== M·∫™U 0 ===============\n",
      "S·ªë token g·ªëc (∆∞·ªõc t√≠nh): 216\n",
      "S·ªë token sau khi x·ª≠ l√Ω (gi·ªõi h·∫°n b·ªüi max_len=512): 235\n",
      "‚úÖ  OK: ƒê·ªô d√†i m·∫´u n·∫±m trong gi·ªõi h·∫°n, kh√¥ng b·ªã c·∫Øt.\n",
      "\n",
      "--- VƒÉn b·∫£n G·ªêC  ---\n",
      "C√¢u h·ªèi: N∆∞·ªõc ch·∫•m ƒë∆∞·ª£c pha tr·ªôn b·ªüi nh·ªØng nguy√™n li·ªáu g√¨? Ng·ªØ c·∫£nh: ·∫®m th·ª±c Vi·ªát Nam ƒë·∫∑c tr∆∞ng v·ªõi vi·ªác s·ª≠ d·ª•ng r·∫•t nhi·ªÅu lo·∫°i m·∫Øm, n∆∞·ªõc ch·∫•m t·ª´ lo√£ng ƒë·∫øn ƒë·∫∑c. M·∫Øm, n∆∞·ªõc ch·∫•m c√≥ th·ªÉ d√πng nguy√™n ch·∫•t, c√≥ th·ªÉ ch∆∞ng l√™n ho·∫∑c pha ch·∫ø, ph·ªëi tr·ªôn v·ªõi ·ªõt, g·ª´ng ho·∫∑c t·ªèi, h·∫°t ti√™u, ƒë∆∞·ªùng, chanh ho·∫∑c gi·∫•m. Ng∆∞·ªùi s√†nh n·ªôi tr·ª£ th∆∞·ªùng c√≥ kinh nghi·ªám ƒë·∫∑c bi·ªát ƒë·ªÉ pha ch·∫ø n∆∞·ªõc ch·∫•m t√πy theo m√≥n ƒÉn. Th·∫≠m ch√≠, c√πng nguy√™n li·ªáu l√† n∆∞·ªõc m·∫Øm, d·∫•m, ƒë∆∞·ªùng, t·ªèi, ·ªõt, d√πng ƒë·ªÉ ƒÉn v·ªõi m√≥n g√¨ th√¨ t·ª∑ l·ªá c√°c th√†nh ph·∫ßn pha ch·∫ø c≈©ng kh√°c nhau, nh∆∞ khi d√πng ch·∫•m rau s·ªëng th√¨ pha nh·∫°t, ƒÉn v·ªõi b√∫n ch·∫£ th√¨ th√™m chua. [SEP] N∆∞·ªõc ch·∫•m c√≤n c√≥ th·ªÉ pha th√™m v·ªõi d·∫ßu m√® ƒë·ªÉ t·∫°o h∆∞∆°ng th∆°m ƒë·∫∑c bi·ªát, ho·∫∑c s·ª≠ d·ª•ng n∆∞·ªõc d·ª´a t∆∞∆°i ƒë·ªÉ l√†m d·ªãu v·ªã, t·∫°o ra h∆∞∆°ng v·ªã ƒë·ªôc ƒë√°o cho m√≥n ƒÉn.\n",
      "\n",
      "--- VƒÉn b·∫£n SAU KHI DECODE t·ª´ input_ids ---\n",
      "<s><mask> ! D·ª±a tr√™n th√¥ng tin: \"C√¢u h·ªèi: N∆∞·ªõc ch·∫•m ƒë∆∞·ª£c pha tr·ªôn b·ªüi nh·ªØng nguy√™n li·ªáu g√¨? Ng·ªØ c·∫£nh: ·∫®m th·ª±c Vi·ªát Nam ƒë·∫∑c tr∆∞ng v·ªõi vi·ªác s·ª≠ d·ª•ng r·∫•t nhi·ªÅu lo·∫°i m·∫Øm, n∆∞·ªõc ch·∫•m t·ª´ lo√£ng ƒë·∫øn ƒë·∫∑c. M·∫Øm, n∆∞·ªõc ch·∫•m c√≥ th·ªÉ d√πng nguy√™n ch·∫•t, c√≥ th·ªÉ ch∆∞ng l√™n ho·∫∑c pha ch·∫ø, ph·ªëi tr·ªôn v·ªõi ·ªõt, g·ª´ng ho·∫∑c t·ªèi, h·∫°t ti√™u, ƒë∆∞·ªùng, chanh ho·∫∑c gi·∫•m. Ng∆∞·ªùi s√†nh n·ªôi tr·ª£ th∆∞·ªùng c√≥ kinh nghi·ªám ƒë·∫∑c bi·ªát ƒë·ªÉ pha ch·∫ø n∆∞·ªõc ch·∫•m t√πy theo m√≥n ƒÉn. Th·∫≠m ch√≠, c√πng nguy√™n li·ªáu l√† n∆∞·ªõc m·∫Øm, d·∫•m, ƒë∆∞·ªùng, t·ªèi, ·ªõt, d√πng ƒë·ªÉ ƒÉn v·ªõi m√≥n g√¨ th√¨ t·ª∑ l·ªá c√°c th√†nh ph·∫ßn pha ch·∫ø c≈©ng kh√°c nhau, nh∆∞ khi d√πng ch·∫•m rau s·ªëng th√¨ pha nh·∫°t, ƒÉn v·ªõi b√∫n ch·∫£ th√¨ th√™m chua.\", c√¢u tr·∫£ l·ªùi \"N∆∞·ªõc ch·∫•m c√≤n c√≥ th·ªÉ pha th√™m v·ªõi d·∫ßu m√® ƒë·ªÉ t·∫°o h∆∞∆°ng th∆°m ƒë·∫∑c bi·ªát, ho·∫∑c s·ª≠ d·ª•ng n∆∞·ªõc d·ª´a t∆∞∆°i ƒë·ªÉ l√†m d·ªãu v·ªã, t·∫°o ra h∆∞∆°ng v·ªã ƒë·ªôc ƒë√°o cho m√≥n ƒÉn.\" c√≥ ƒë√∫ng kh√¥ng?</s>\n",
      "\n",
      "=============== M·∫™U 1 ===============\n",
      "S·ªë token g·ªëc (∆∞·ªõc t√≠nh): 273\n",
      "S·ªë token sau khi x·ª≠ l√Ω (gi·ªõi h·∫°n b·ªüi max_len=512): 292\n",
      "‚úÖ  OK: ƒê·ªô d√†i m·∫´u n·∫±m trong gi·ªõi h·∫°n, kh√¥ng b·ªã c·∫Øt.\n",
      "\n",
      "--- VƒÉn b·∫£n G·ªêC  ---\n",
      "C√¢u h·ªèi: Newt0n d√£ hoan th√†n phuong phap c·ªßa ai? Ng·ªØ c·∫£nh: B·ªën quy t·∫Øc s√∫c t√≠ch v√† t·ªïng qu√°t cho nghi√™n c·ª©u khoa h·ªçc n√†y ƒë√£ l√† m·ªôt cu·ªôc c√°ch m·∫°ng v·ªÅ t∆∞ duy th·ª±c s·ª± v√†o th·ªùi ƒëi·ªÉm b·∫•y gi·ªù. Th·ª±c hi·ªán c√°c quy t·∫Øc n√†y, Newton ƒë√£ h√¨nh th√†nh ƒë∆∞·ª£c c√°c ƒë·ªãnh lu·∫≠t t·ªïng qu√°t c·ªßa t·ª± nhi√™n v√† gi·∫£i th√≠ch ƒë∆∞·ª£c g·∫ßn nh∆∞ t·∫•t c·∫£ c√°c b√†i to√°n khoa h·ªçc v√†o th·ªùi c·ªßa √¥ng. Newton c√≤n ƒëi xa h∆°n vi·ªác ch·ªâ ƒë∆∞a ra c√°c quy t·∫Øc cho l√Ω lu·∫≠n, √¥ng ƒë√£ mi√™u t·∫£ c√°ch √°p d·ª•ng ch√∫ng trong vi·ªác gi·∫£i quy·∫øt m·ªôt b√†i to√°n c·ª• th·ªÉ. Ph∆∞∆°ng ph√°p gi·∫£i t√≠ch m√† √¥ng s√°ng t·∫°o v∆∞·ª£t tr·ªôi c√°c ph∆∞∆°ng ph√°p mang t√≠nh tri·∫øt l√Ω h∆°n l√† t√≠nh ch√≠nh x√°c khoa h·ªçc c·ªßa Aristoteles v√† Thomas Aquinas. Newton ƒë√£ ho√†n thi·ªán ph∆∞∆°ng ph√°p th·ª±c nghi·ªám c·ªßa Galileo Galilei, t·∫°o ra ph∆∞∆°ng ph√°p t·ªïng h·ª£p v·∫´n c√≤n ƒë∆∞·ª£c s·ª≠ d·ª•ng cho ƒë·∫øn ng√†y nay trong khoa h·ªçc. Nh·ªØng c√¢u ch·ªØ sau ƒë√¢y trong quy·ªÉn Opticks (Quang h·ªçc) c·ªßa √¥ng c√≥ th·ªÉ d·ªÖ d√†ng b·ªã nh·∫ßm l·∫´n v·ªõi tr√¨nh b√†y hi·ªán ƒë·∫°i c·ªßa ph∆∞∆°ng ph√°p nghi√™n c·ª©u th·ªùi nay, n·∫øu Newton d√πng t·ª´ \"khoa h·ªçc\" thay cho \"tri·∫øt l√Ω v·ªÅ t·ª± nhi√™n\": [SEP] Newton ƒë√£ ho√†n thi·ªán ph∆∞∆°ng ph√°p th·ª±c nghi·ªám c·ªßa Galileo Galilei.\n",
      "\n",
      "--- VƒÉn b·∫£n SAU KHI DECODE t·ª´ input_ids ---\n",
      "<s><mask> ! D·ª±a tr√™n th√¥ng tin: \"C√¢u h·ªèi: Newt0n d√£ hoan th√†n phuong phap c·ªßa ai? Ng·ªØ c·∫£nh: B·ªën quy t·∫Øc s√∫c t√≠ch v√† t·ªïng qu√°t cho nghi√™n c·ª©u khoa h·ªçc n√†y ƒë√£ l√† m·ªôt cu·ªôc c√°ch m·∫°ng v·ªÅ t∆∞ duy th·ª±c s·ª± v√†o th·ªùi ƒëi·ªÉm b·∫•y gi·ªù. Th·ª±c hi·ªán c√°c quy t·∫Øc n√†y, Newton ƒë√£ h√¨nh th√†nh ƒë∆∞·ª£c c√°c ƒë·ªãnh lu·∫≠t t·ªïng qu√°t c·ªßa t·ª± nhi√™n v√† gi·∫£i th√≠ch ƒë∆∞·ª£c g·∫ßn nh∆∞ t·∫•t c·∫£ c√°c b√†i to√°n khoa h·ªçc v√†o th·ªùi c·ªßa √¥ng. Newton c√≤n ƒëi xa h∆°n vi·ªác ch·ªâ ƒë∆∞a ra c√°c quy t·∫Øc cho l√Ω lu·∫≠n, √¥ng ƒë√£ mi√™u t·∫£ c√°ch √°p d·ª•ng ch√∫ng trong vi·ªác gi·∫£i quy·∫øt m·ªôt b√†i to√°n c·ª• th·ªÉ. Ph∆∞∆°ng ph√°p gi·∫£i t√≠ch m√† √¥ng s√°ng t·∫°o v∆∞·ª£t tr·ªôi c√°c ph∆∞∆°ng ph√°p mang t√≠nh tri·∫øt l√Ω h∆°n l√† t√≠nh ch√≠nh x√°c khoa h·ªçc c·ªßa Aristoteles v√† Thomas Aquinas. Newton ƒë√£ ho√†n thi·ªán ph∆∞∆°ng ph√°p th·ª±c nghi·ªám c·ªßa Galileo Galilei, t·∫°o ra ph∆∞∆°ng ph√°p t·ªïng h·ª£p v·∫´n c√≤n ƒë∆∞·ª£c s·ª≠ d·ª•ng cho ƒë·∫øn ng√†y nay trong khoa h·ªçc. Nh·ªØng c√¢u ch·ªØ sau ƒë√¢y trong quy·ªÉn Opticks (Quang h·ªçc) c·ªßa √¥ng c√≥ th·ªÉ d·ªÖ d√†ng b·ªã nh·∫ßm l·∫´n v·ªõi tr√¨nh b√†y hi·ªán ƒë·∫°i c·ªßa ph∆∞∆°ng ph√°p nghi√™n c·ª©u th·ªùi nay, n·∫øu Newton d√πng t·ª´ \"khoa h·ªçc\" thay cho \"tri·∫øt l√Ω v·ªÅ t·ª± nhi√™n\":\", c√¢u tr·∫£ l·ªùi \"Newton ƒë√£ ho√†n thi·ªán ph∆∞∆°ng ph√°p th·ª±c nghi·ªám c·ªßa Galileo Galilei.\" c√≥ ƒë√∫ng kh√¥ng?</s>\n",
      "\n",
      "=============== M·∫™U 2 ===============\n",
      "S·ªë token g·ªëc (∆∞·ªõc t√≠nh): 260\n",
      "S·ªë token sau khi x·ª≠ l√Ω (gi·ªõi h·∫°n b·ªüi max_len=512): 279\n",
      "‚úÖ  OK: ƒê·ªô d√†i m·∫´u n·∫±m trong gi·ªõi h·∫°n, kh√¥ng b·ªã c·∫Øt.\n",
      "\n",
      "--- VƒÉn b·∫£n G·ªêC  ---\n",
      "C√¢u h·ªèi: Bi·ªÉn ƒê√¥ng n·∫±m v·ªÅ ph√≠a n√†o c·ªßa ƒë·∫°i l·ª•c Trung Hoa v√† c√≥ ph·∫£i n√≥ thu·ªôc ch·ªß quy·ªÅn c·ªßa Trung Qu·ªëc v√¨ t√™n g·ªçi qu·ªëc t·∫ø l√† bi·ªÉn Nam Trung Hoa kh√¥ng? Ng·ªØ c·∫£nh: T√™n g·ªçi qu·ªëc t·∫ø c·ªßa Bi·ªÉn ƒê√¥ng ra ƒë·ªùi t·ª´ nhi·ªÅu th·∫ø k·ª∑ tr∆∞·ªõc, l√† bi·ªÉn Nam Trung Hoa (South China Sea) hay g·ªçi t·∫Øt l√† bi·ªÉn Hoa Nam v√¨ th·ªùi b·∫•y gi·ªù Trung Qu·ªëc l√† n∆∞·ªõc r·ªông l·ªõn nh·∫•t, ph√°t tri·ªÉn nh·∫•t trong khu v·ª±c v√† ƒë√£ c√≥ giao th∆∞∆°ng v·ªõi ph∆∞∆°ng T√¢y qua con ƒë∆∞·ªùng t∆° l·ª•a. T√™n g·ªçi nhi·ªÅu bi·ªÉn, ƒë·∫°i d∆∞∆°ng v·ªën cƒÉn c·ª© v√†o v·ªã tr√≠ c·ªßa ch√∫ng so v·ªõi c√°c v√πng ƒë·∫•t g·∫ßn ƒë√≥ cho d·ªÖ tra c·ª©u, kh√¥ng c√≥ √Ω n√≥i v·ªÅ ch·ªß quy·ªÅn, c·∫ßn tr√°nh nh·∫ßm l·∫´n. C√≥ th·ªÉ k·ªÉ ra c√°c th√≠ d·ª• l√† ·∫§n ƒê·ªô D∆∞∆°ng, l√† ƒë·∫°i d∆∞∆°ng ·ªü ph√≠a nam ·∫§n ƒê·ªô, gi√°p nhi·ªÅu n∆∞·ªõc ·ªü ch√¢u √Å v√† ch√¢u Phi, kh√¥ng ph·∫£i l√† c·ªßa ri√™ng n∆∞·ªõc ·∫§n ƒê·ªô; hay bi·ªÉn Nh·∫≠t B·∫£n, ƒë∆∞·ª£c bao quanh b·ªüi Nga, B·∫Øc Tri·ªÅu Ti√™n, H√†n Qu·ªëc v√† Nh·∫≠t B·∫£n. [SEP] Bi·ªÉn ƒê√¥ng n·∫±m ·ªü ph√≠a ƒë√¥ng c·ªßa ƒë·∫°i l·ª•c Trung Hoa v√† thu·ªôc ch·ªß quy·ªÅn c·ªßa Trung Qu·ªëc v√¨ t√™n g·ªçi qu·ªëc t·∫ø l√† bi·ªÉn Nam Trung Hoa, ph·∫£n √°nh quy·ªÅn s·ªü h·ªØu c·ªßa Trung Qu·ªëc t·ª´ x∆∞a.\n",
      "\n",
      "--- VƒÉn b·∫£n SAU KHI DECODE t·ª´ input_ids ---\n",
      "<s><mask> ! D·ª±a tr√™n th√¥ng tin: \"C√¢u h·ªèi: Bi·ªÉn ƒê√¥ng n·∫±m v·ªÅ ph√≠a n√†o c·ªßa ƒë·∫°i l·ª•c Trung Hoa v√† c√≥ ph·∫£i n√≥ thu·ªôc ch·ªß quy·ªÅn c·ªßa Trung Qu·ªëc v√¨ t√™n g·ªçi qu·ªëc t·∫ø l√† bi·ªÉn Nam Trung Hoa kh√¥ng? Ng·ªØ c·∫£nh: T√™n g·ªçi qu·ªëc t·∫ø c·ªßa Bi·ªÉn ƒê√¥ng ra ƒë·ªùi t·ª´ nhi·ªÅu th·∫ø k·ª∑ tr∆∞·ªõc, l√† bi·ªÉn Nam Trung Hoa (South China Sea) hay g·ªçi t·∫Øt l√† bi·ªÉn Hoa Nam v√¨ th·ªùi b·∫•y gi·ªù Trung Qu·ªëc l√† n∆∞·ªõc r·ªông l·ªõn nh·∫•t, ph√°t tri·ªÉn nh·∫•t trong khu v·ª±c v√† ƒë√£ c√≥ giao th∆∞∆°ng v·ªõi ph∆∞∆°ng T√¢y qua con ƒë∆∞·ªùng t∆° l·ª•a. T√™n g·ªçi nhi·ªÅu bi·ªÉn, ƒë·∫°i d∆∞∆°ng v·ªën cƒÉn c·ª© v√†o v·ªã tr√≠ c·ªßa ch√∫ng so v·ªõi c√°c v√πng ƒë·∫•t g·∫ßn ƒë√≥ cho d·ªÖ tra c·ª©u, kh√¥ng c√≥ √Ω n√≥i v·ªÅ ch·ªß quy·ªÅn, c·∫ßn tr√°nh nh·∫ßm l·∫´n. C√≥ th·ªÉ k·ªÉ ra c√°c th√≠ d·ª• l√† ·∫§n ƒê·ªô D∆∞∆°ng, l√† ƒë·∫°i d∆∞∆°ng ·ªü ph√≠a nam ·∫§n ƒê·ªô, gi√°p nhi·ªÅu n∆∞·ªõc ·ªü ch√¢u √Å v√† ch√¢u Phi, kh√¥ng ph·∫£i l√† c·ªßa ri√™ng n∆∞·ªõc ·∫§n ƒê·ªô; hay bi·ªÉn Nh·∫≠t B·∫£n, ƒë∆∞·ª£c bao quanh b·ªüi Nga, B·∫Øc Tri·ªÅu Ti√™n, H√†n Qu·ªëc v√† Nh·∫≠t B·∫£n.\", c√¢u tr·∫£ l·ªùi \"Bi·ªÉn ƒê√¥ng n·∫±m ·ªü ph√≠a ƒë√¥ng c·ªßa ƒë·∫°i l·ª•c Trung Hoa v√† thu·ªôc ch·ªß quy·ªÅn c·ªßa Trung Qu·ªëc v√¨ t√™n g·ªçi qu·ªëc t·∫ø l√† bi·ªÉn Nam Trung Hoa, ph·∫£n √°nh quy·ªÅn s·ªü h·ªØu c·ªßa Trung Qu·ªëc t·ª´ x∆∞a.\" c√≥ ƒë√∫ng kh√¥ng?</s>\n",
      "\n",
      "=============== M·∫™U 3 ===============\n",
      "S·ªë token g·ªëc (∆∞·ªõc t√≠nh): 402\n",
      "S·ªë token sau khi x·ª≠ l√Ω (gi·ªõi h·∫°n b·ªüi max_len=512): 420\n",
      "‚úÖ  OK: ƒê·ªô d√†i m·∫´u n·∫±m trong gi·ªõi h·∫°n, kh√¥ng b·ªã c·∫Øt.\n",
      "\n",
      "--- VƒÉn b·∫£n G·ªêC  ---\n",
      "C√¢u h·ªèi: ƒêo·∫°n ghi √¢m cu·ªôc n√≥i chuy·ªán v·ªõi b√† c·ªßa Obama l√† do ai l√†m ra? Ng·ªØ c·∫£nh: Th√°ng 4 nƒÉm 2011, Trump ƒë·∫∑t d·∫•u h·ªèi v·ªÅ b·∫±ng ch·ª©ng qu·ªëc t·ªãch c·ªßa T·ªïng th·ªëng Barack Obama, c√°o bu·ªôc r·∫±ng \"b√† c·ªßa √¥ng ta ·ªü Kenya n√≥i r·∫±ng √¥ng ta sinh ra ·ªü Kenya v√† b√† ·∫•y ƒë√£ ·ªü ƒë√≥ v√† t·∫≠n m·∫Øt ch·ª©ng ki·∫øn\" (Lu·∫≠n ƒëi·ªÉm c·ªßa Trump b·∫Øt ngu·ªìn t·ª´ ƒëo·∫°n ghi √¢m b√†i ph·ªèng v·∫•n qua ƒëi·ªán tho·∫°i v·ªõi b√† c·ªßa Obama, s·∫£n ph·∫©m c·ªßa m·ªôt m·ª•c s∆∞ bang Pennsylvania ph·∫£n ƒë·ªëi vi·ªác b·∫ßu Obama). Trump c≈©ng ho√†i nghi vi·ªác li·ªáu Obama c√≥ ƒë·ªß ƒëi·ªÉm ƒë·∫ßu v√†o Tr∆∞·ªùng Lu·∫≠t Harvard hay kh√¥ng. Trump n√≥i r·∫±ng √¥ng ƒë√£ g·ª≠i m·ªôt nh√≥m ƒëi·ªÅu tra t∆∞ nh√¢n t·ªõi Hawaii, n∆°i sinh ghi tr√™n gi·∫•y t·ªù c·ªßa Obama v√† chia s·∫ª v·ªõi The Today Show \"h·ªç kh√¥ng th·ªÉ tin v√†o nh·ªØng g√¨ h·ªç t√¨m th·∫•y\". Ng√†y 25 th√°ng 4 nƒÉm 2011, Trump k√™u g·ªçi Obama h√£y k·∫øt th√∫c v·∫•n ƒë·ªÅ qu·ªëc t·ªãch b·∫±ng vi·ªác c√¥ng b·ªë b·∫£n ƒë·∫ßy ƒë·ªß gi·∫•y khai sinh c·ªßa m√¨nh. Hai ng√†y sau, Obama ƒë∆∞a ra th√¥ng c√°o ch√≠nh th·ª©c trong m·ªôt n·ªó l·ª±c c·ªßa Nh√† Tr·∫Øng nh·∫±m kh√©p l·∫°i s·ª± v·ª• v√† c√¥ng b·ªë b·∫£n ƒë·∫ßy ƒë·ªß gi·∫•y khai sinh c·ªßa m√¨nh. Trump b√†y t·ªè s·ª± t·ª± h√†o v·ªõi vai tr√≤ c·ªßa √¥ng trong vi·ªác gi·∫•y khai sinh ƒë∆∞·ª£c c√¥ng b·ªë qua m·ªôt bu·ªïi h·ªçp b√°o ngay sau ƒë√≥, n√≥i r·∫±ng √¥ng mong r·∫±ng n√≥ \"h·ª£p l√Ω\" v√† \"ch√∫ng ta ph·∫£i t·∫≠n m·∫Øt th·∫•y, n√≥ c√≥ th·∫≠t hay kh√¥ng?\" Khi ƒë∆∞·ª£c h·ªèi v√†o th√°ng 7 nƒÉm 2015 c√≥ ƒë√∫ng Obama sinh ra ·ªü M·ªπ kh√¥ng, Trump n√≥i: \"T√¥i th·∫≠t s·ª± kh√¥ng bi·∫øt. √ù t√¥i l√†, t√¥i kh√¥ng hi·ªÉu t·∫°i sao tr∆∞·ªõc ƒë√≥ √¥ng ta kh√¥ng c√¥ng b·ªë gi·∫•y t·ªù c·ªßa m√¨nh\". [SEP] ƒêo·∫°n ghi √¢m cu·ªôc n√≥i chuy·ªán v·ªõi b√† c·ªßa Obama ƒë∆∞·ª£c th·ª±c hi·ªán b·ªüi m·ªôt nh√† b√°o ƒëi·ªÅu tra ƒë·ªôc l·∫≠p t·ª´ New York, ng∆∞·ªùi ƒë√£ tuy√™n b·ªë c√≥ b·∫±ng ch·ª©ng m·ªõi v·ªÅ n∆°i sinh c·ªßa Obama, kh√°c v·ªõi nh·ªØng g√¨ ƒë√£ bi·∫øt tr∆∞·ªõc ƒë√≥.\n",
      "\n",
      "--- VƒÉn b·∫£n SAU KHI DECODE t·ª´ input_ids ---\n",
      "<s><mask> ! D·ª±a tr√™n th√¥ng tin: \"C√¢u h·ªèi: ƒêo·∫°n ghi √¢m cu·ªôc n√≥i chuy·ªán v·ªõi b√† c·ªßa Obama l√† do ai l√†m ra? Ng·ªØ c·∫£nh: Th√°ng 4 nƒÉm 2011, Trump ƒë·∫∑t d·∫•u h·ªèi v·ªÅ b·∫±ng ch·ª©ng qu·ªëc t·ªãch c·ªßa T·ªïng th·ªëng Barack Obama, c√°o bu·ªôc r·∫±ng \"b√† c·ªßa √¥ng ta ·ªü Kenya n√≥i r·∫±ng √¥ng ta sinh ra ·ªü Kenya v√† b√† ·∫•y ƒë√£ ·ªü ƒë√≥ v√† t·∫≠n m·∫Øt ch·ª©ng ki·∫øn\" (Lu·∫≠n ƒëi·ªÉm c·ªßa Trump b·∫Øt ngu·ªìn t·ª´ ƒëo·∫°n ghi √¢m b√†i ph·ªèng v·∫•n qua ƒëi·ªán tho·∫°i v·ªõi b√† c·ªßa Obama, s·∫£n ph·∫©m c·ªßa m·ªôt m·ª•c s∆∞ bang Pennsylvania ph·∫£n ƒë·ªëi vi·ªác b·∫ßu Obama). Trump c≈©ng ho√†i nghi vi·ªác li·ªáu Obama c√≥ ƒë·ªß ƒëi·ªÉm ƒë·∫ßu v√†o Tr∆∞·ªùng Lu·∫≠t Harvard hay kh√¥ng. Trump n√≥i r·∫±ng √¥ng ƒë√£ g·ª≠i m·ªôt nh√≥m ƒëi·ªÅu tra t∆∞ nh√¢n t·ªõi Hawaii, n∆°i sinh ghi tr√™n gi·∫•y t·ªù c·ªßa Obama v√† chia s·∫ª v·ªõi The Today Show \"h·ªç kh√¥ng th·ªÉ tin v√†o nh·ªØng g√¨ h·ªç t√¨m th·∫•y\". Ng√†y 25 th√°ng 4 nƒÉm 2011, Trump k√™u g·ªçi Obama h√£y k·∫øt th√∫c v·∫•n ƒë·ªÅ qu·ªëc t·ªãch b·∫±ng vi·ªác c√¥ng b·ªë b·∫£n ƒë·∫ßy ƒë·ªß gi·∫•y khai sinh c·ªßa m√¨nh. Hai ng√†y sau, Obama ƒë∆∞a ra th√¥ng c√°o ch√≠nh th·ª©c trong m·ªôt n·ªó l·ª±c c·ªßa Nh√† Tr·∫Øng nh·∫±m kh√©p l·∫°i s·ª± v·ª• v√† c√¥ng b·ªë b·∫£n ƒë·∫ßy ƒë·ªß gi·∫•y khai sinh c·ªßa m√¨nh. Trump b√†y t·ªè s·ª± t·ª± h√†o v·ªõi vai tr√≤ c·ªßa √¥ng trong vi·ªác gi·∫•y khai sinh ƒë∆∞·ª£c c√¥ng b·ªë qua m·ªôt bu·ªïi h·ªçp b√°o ngay sau ƒë√≥, n√≥i r·∫±ng √¥ng mong r·∫±ng n√≥ \"h·ª£p l√Ω\" v√† \"ch√∫ng ta ph·∫£i t·∫≠n m·∫Øt th·∫•y, n√≥ c√≥ th·∫≠t hay kh√¥ng?\" Khi ƒë∆∞·ª£c h·ªèi v√†o th√°ng 7 nƒÉm 2015 c√≥ ƒë√∫ng Obama sinh ra ·ªü M·ªπ kh√¥ng, Trump n√≥i: \"T√¥i th·∫≠t s·ª± kh√¥ng bi·∫øt. √ù t√¥i l√†, t√¥i kh√¥ng hi·ªÉu t·∫°i sao tr∆∞·ªõc ƒë√≥ √¥ng ta kh√¥ng c√¥ng b·ªë gi·∫•y t·ªù c·ªßa m√¨nh\".\", c√¢u tr·∫£ l·ªùi \"ƒêo·∫°n ghi √¢m cu·ªôc n√≥i chuy·ªán v·ªõi b√† c·ªßa Obama ƒë∆∞·ª£c th·ª±c hi·ªán b·ªüi m·ªôt nh√† b√°o ƒëi·ªÅu tra ƒë·ªôc l·∫≠p t·ª´ New York, ng∆∞·ªùi ƒë√£ tuy√™n b·ªë c√≥ b·∫±ng ch·ª©ng m·ªõi v·ªÅ n∆°i sinh c·ªßa Obama, kh√°c v·ªõi nh·ªØng g√¨ ƒë√£ bi·∫øt tr∆∞·ªõc ƒë√≥.\" c√≥ ƒë√∫ng kh√¥ng?</s>\n",
      "\n",
      "=============== M·∫™U 4 ===============\n",
      "S·ªë token g·ªëc (∆∞·ªõc t√≠nh): 417\n",
      "S·ªë token sau khi x·ª≠ l√Ω (gi·ªõi h·∫°n b·ªüi max_len=512): 436\n",
      "‚úÖ  OK: ƒê·ªô d√†i m·∫´u n·∫±m trong gi·ªõi h·∫°n, kh√¥ng b·ªã c·∫Øt.\n",
      "\n",
      "--- VƒÉn b·∫£n G·ªêC  ---\n",
      "C√¢u h·ªèi: Khi ƒë·∫øn khoe t√†i t·∫°i Montr√©al, c√°c nh·∫°c sƒ©, ngh·ªá sƒ© ƒë√£ s·ª≠ d·ª•ng ng√¥n ng·ªØ Nh·∫≠t B·∫£n, c√≥ ƒë√∫ng kh√¥ng? Ng·ªØ c·∫£nh: Sang ƒë·∫øn m√πa h√® th√¨ Montr√©al l√∫c n√†o c≈©ng c√≥ √≠t nh·∫•t m·ªôt h·ªôi h√®. Trong khi c√°c th√†nh ph·ªë kh√°c ch·ªâ c√≥ m·ªôt, Montr√©al c√≥ 3 li√™n hoan phim di·ªÖn ra h√†ng nƒÉm, trong ƒë√≥ Li√™n hoan phim th·∫ø gi·ªõi Montr√©al (Festival du Film International de Montr√©al) - ƒë·ª©ng th·ª© ba sau Li√™n hoan phim Cannes v√† Li√™n hoan phim qu·ªëc t·∫ø Toronto - l√† quan tr·ªçng nh·∫•t. ƒê·∫°i h·ªôi nh·∫°c Jazz Montr√©al (Montreal Jazz Festival) - m·ªôt trong h√†ng ch·ª•c c√°c nh·∫°c h·ªôi kh√°c - thu h√∫t h√†ng trƒÉm ng√†n ng∆∞·ªùi m·ªói nƒÉm. Ng√†y Canada Day l√† m·ªôt ng√†y m·ªçi ng∆∞·ªùi ngh·ªâ ng∆°i nh∆∞ng ng√†y Th√°nh b·ªïn m·∫°ng c·ªßa Qu√©bec (St. Jean Bapstiste) l·∫°i l√† m·ªôt d·ªãp ƒë·ªÉ m·ªçi ng∆∞·ªùi vui ch∆°i, nh·∫•t l√† ·ªü nh·ªØng khu ƒë√¥ng d√¢n n√≥i ti·∫øng Ph√°p. Francopholie l√† m·ªôt d·ªãp ƒë·ªÉ c√°c nh·∫°c sƒ©, ngh·ªá sƒ© n√≥i ti·∫øng Ph√°p tr√™n to√†n th·∫ø gi·ªõi ƒë·∫øn khoe t√†i t·∫°i Montr√©al. Tri·ªÉn l√£m ngh·ªá thu·∫≠t ph√°o b√¥ng qu·ªëc t·∫ø (v·ªõi nh·∫°c) di·ªÖn ra h√†ng tu·∫ßn trong th√°ng 7 v√† th√°ng 8. Montr√©al c≈©ng l√† m·ªôt ƒë·ªãa ƒëi·ªÉm c·ªßa lo·∫°i ƒëua xe nhanh nh·∫•t v√† t·ªën ti·ªÅn nh·∫•t tr√™n th·∫ø gi·ªõi: Formula One. H√†ng nƒÉm c·∫£ trƒÉm ng√†n ng∆∞·ªùi tr√™n kh·∫Øp th·∫ø gi·ªõi k√©o nhau ƒë·∫øn Montr√©al ƒë·ªÉ xem c√°c tay l√°i th∆∞·ª£ng th·∫∑ng ƒëua t√†i v·ªõi t·ªëc ƒë·ªô h∆°n 300 km/gi·ªù. H·∫ßu nh∆∞ kh√¥ng c√≥ tay kh√¥i h√†i n√†o ·ªü B·∫Øc M·ªπ kh√¥ng tham d·ª± Juste pour rire/Just For Laugh di·ªÖn ra v√†o th√°ng 8 h√†ng nƒÉm t·∫°i Montr√©al. Trong c√°c h·ªôi h√® c·ªßa c√°c d√¢n ƒë·ªãnh c∆∞ th√¨ Tu·∫ßn l·ªÖ c·ªßa √ù v√† ng√†y ƒê·ªôc l·∫≠p c·ªßa Hy L·∫°p l√† hai l·ªÖ h·ªôi to nh·∫•t. [SEP] M·∫∑c d√π c√°c ngh·ªá sƒ© ch·ªß y·∫øu s·ª≠ d·ª•ng ti·∫øng Ph√°p t·∫°i Francopholie, nh∆∞ng m·ªôt s·ªë ngh·ªá sƒ© qu·ªëc t·∫ø c≈©ng bi·ªÉu di·ªÖn b·∫±ng ti·∫øng Nh·∫≠t v√† c√°c ng√¥n ng·ªØ kh√°c ƒë·ªÉ t√¥n vinh s·ª± ƒëa d·∫°ng vƒÉn h√≥a c·ªßa Montr√©al.\n",
      "\n",
      "--- VƒÉn b·∫£n SAU KHI DECODE t·ª´ input_ids ---\n",
      "<s><mask> ! D·ª±a tr√™n th√¥ng tin: \"C√¢u h·ªèi: Khi ƒë·∫øn khoe t√†i t·∫°i Montr√©al, c√°c nh·∫°c sƒ©, ngh·ªá sƒ© ƒë√£ s·ª≠ d·ª•ng ng√¥n ng·ªØ Nh·∫≠t B·∫£n, c√≥ ƒë√∫ng kh√¥ng? Ng·ªØ c·∫£nh: Sang ƒë·∫øn m√πa h√® th√¨ Montr√©al l√∫c n√†o c≈©ng c√≥ √≠t nh·∫•t m·ªôt h·ªôi h√®. Trong khi c√°c th√†nh ph·ªë kh√°c ch·ªâ c√≥ m·ªôt, Montr√©al c√≥ 3 li√™n hoan phim di·ªÖn ra h√†ng nƒÉm, trong ƒë√≥ Li√™n hoan phim th·∫ø gi·ªõi Montr√©al (Festival du Film International de Montr√©al) - ƒë·ª©ng th·ª© ba sau Li√™n hoan phim Cannes v√† Li√™n hoan phim qu·ªëc t·∫ø Toronto - l√† quan tr·ªçng nh·∫•t. ƒê·∫°i h·ªôi nh·∫°c Jazz Montr√©al (Montreal Jazz Festival) - m·ªôt trong h√†ng ch·ª•c c√°c nh·∫°c h·ªôi kh√°c - thu h√∫t h√†ng trƒÉm ng√†n ng∆∞·ªùi m·ªói nƒÉm. Ng√†y Canada Day l√† m·ªôt ng√†y m·ªçi ng∆∞·ªùi ngh·ªâ ng∆°i nh∆∞ng ng√†y Th√°nh b·ªïn m·∫°ng c·ªßa Qu√©bec (St. Jean Bapstiste) l·∫°i l√† m·ªôt d·ªãp ƒë·ªÉ m·ªçi ng∆∞·ªùi vui ch∆°i, nh·∫•t l√† ·ªü nh·ªØng khu ƒë√¥ng d√¢n n√≥i ti·∫øng Ph√°p. Francopholie l√† m·ªôt d·ªãp ƒë·ªÉ c√°c nh·∫°c sƒ©, ngh·ªá sƒ© n√≥i ti·∫øng Ph√°p tr√™n to√†n th·∫ø gi·ªõi ƒë·∫øn khoe t√†i t·∫°i Montr√©al. Tri·ªÉn l√£m ngh·ªá thu·∫≠t ph√°o b√¥ng qu·ªëc t·∫ø (v·ªõi nh·∫°c) di·ªÖn ra h√†ng tu·∫ßn trong th√°ng 7 v√† th√°ng 8. Montr√©al c≈©ng l√† m·ªôt ƒë·ªãa ƒëi·ªÉm c·ªßa lo·∫°i ƒëua xe nhanh nh·∫•t v√† t·ªën ti·ªÅn nh·∫•t tr√™n th·∫ø gi·ªõi: Formula One. H√†ng nƒÉm c·∫£ trƒÉm ng√†n ng∆∞·ªùi tr√™n kh·∫Øp th·∫ø gi·ªõi k√©o nhau ƒë·∫øn Montr√©al ƒë·ªÉ xem c√°c tay l√°i th∆∞·ª£ng th·∫∑ng ƒëua t√†i v·ªõi t·ªëc ƒë·ªô h∆°n 300 km/gi·ªù. H·∫ßu nh∆∞ kh√¥ng c√≥ tay kh√¥i h√†i n√†o ·ªü B·∫Øc M·ªπ kh√¥ng tham d·ª± Juste pour rire/Just For Laugh di·ªÖn ra v√†o th√°ng 8 h√†ng nƒÉm t·∫°i Montr√©al. Trong c√°c h·ªôi h√® c·ªßa c√°c d√¢n ƒë·ªãnh c∆∞ th√¨ Tu·∫ßn l·ªÖ c·ªßa √ù v√† ng√†y ƒê·ªôc l·∫≠p c·ªßa Hy L·∫°p l√† hai l·ªÖ h·ªôi to nh·∫•t.\", c√¢u tr·∫£ l·ªùi \"M·∫∑c d√π c√°c ngh·ªá sƒ© ch·ªß y·∫øu s·ª≠ d·ª•ng ti·∫øng Ph√°p t·∫°i Francopholie, nh∆∞ng m·ªôt s·ªë ngh·ªá sƒ© qu·ªëc t·∫ø c≈©ng bi·ªÉu di·ªÖn b·∫±ng ti·∫øng Nh·∫≠t v√† c√°c ng√¥n ng·ªØ kh√°c ƒë·ªÉ t√¥n vinh s·ª± ƒëa d·∫°ng vƒÉn h√≥a c·ªßa Montr√©al.\" c√≥ ƒë√∫ng kh√¥ng?</s>\n",
      "\n",
      "===========================================\n",
      "Ki·ªÉm tra ho√†n t·∫•t. H√£y so s√°nh vƒÉn b·∫£n tr√™n ƒë·ªÉ xem c√≥ s·ª± kh√°c bi·ªát ·ªü cu·ªëi chu·ªói kh√¥ng.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Ki·ªÉm tra chi ti·∫øt 5 m·∫´u ƒë·∫ßu ti√™n ƒë·ªÉ so s√°nh tr∆∞·ªõc v√† sau khi x·ª≠ l√Ω ---\")\n",
    "\n",
    "# L·∫•y 5 m·∫´u ƒë·∫ßu ti√™n t·ª´ DataFrame g·ªëc ƒë·ªÉ so s√°nh\n",
    "num_samples_to_check = 5\n",
    "for i in range(num_samples_to_check):\n",
    "    print(f\"\\n=============== M·∫™U {i} ===============\")\n",
    "\n",
    "    # 1. L·∫•y d·ªØ li·ªáu g·ªëc t·ª´ DataFrame\n",
    "    original_premise = train_df[\"premise\"].iloc[i]\n",
    "    original_hypothesis = train_df[\"hypothesis\"].iloc[i]\n",
    "    # N·ªëi 2 chu·ªói l·∫°i gi·ªëng c√°ch tokenizer s·∫Ω th·∫•y ch√∫ng\n",
    "    original_combined_text = original_premise + \" [SEP] \" + original_hypothesis\n",
    "\n",
    "    # 2. L·∫•y d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω t·ª´ Dataset\n",
    "    processed_sample = train_dataset[i]\n",
    "    processed_input_ids = processed_sample[\"input_ids\"]\n",
    "\n",
    "    # 3. Gi·∫£i m√£ (decode) c√°c input_ids ƒë√£ x·ª≠ l√Ω tr·ªü l·∫°i th√†nh vƒÉn b·∫£n\n",
    "    decoded_text = tokenizer.decode(processed_input_ids, skip_special_tokens=False)\n",
    "\n",
    "    # 4. So s√°nh v√† in k·∫øt qu·∫£\n",
    "    original_token_count = len(tokenizer.encode(original_premise, original_hypothesis))\n",
    "    processed_token_count = len(processed_input_ids)\n",
    "\n",
    "    print(f\"S·ªë token g·ªëc (∆∞·ªõc t√≠nh): {original_token_count}\")\n",
    "    print(\n",
    "        f\"S·ªë token sau khi x·ª≠ l√Ω (gi·ªõi h·∫°n b·ªüi max_len={cfg.MAX_LENGTH}): {processed_token_count}\"\n",
    "    )\n",
    "\n",
    "    if original_token_count > cfg.MAX_LENGTH:\n",
    "        print(\"‚ö†Ô∏è  C·∫¢NH B√ÅO: M·∫´u n√†y ƒë√£ b·ªã c·∫Øt b·ªõt (truncated)!\")\n",
    "    else:\n",
    "        print(\"‚úÖ  OK: ƒê·ªô d√†i m·∫´u n·∫±m trong gi·ªõi h·∫°n, kh√¥ng b·ªã c·∫Øt.\")\n",
    "\n",
    "    print(\"\\n--- VƒÉn b·∫£n G·ªêC  ---\")\n",
    "    print(original_combined_text)\n",
    "\n",
    "    print(\"\\n--- VƒÉn b·∫£n SAU KHI DECODE t·ª´ input_ids ---\")\n",
    "    print(decoded_text)\n",
    "\n",
    "print(\"\\n===========================================\")\n",
    "print(\n",
    "    \"Ki·ªÉm tra ho√†n t·∫•t. H√£y so s√°nh vƒÉn b·∫£n tr√™n ƒë·ªÉ xem c√≥ s·ª± kh√°c bi·ªát ·ªü cu·ªëi chu·ªói kh√¥ng.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739f76b",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# 4. Thi·∫øt l·∫≠p Hu·∫•n luy·ªán\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62005cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:44:21 - [INFO] - B∆∞·ªõc 4: Thi·∫øt l·∫≠p optimizer, scheduler v√† loss function...\n",
      "2025-10-16 21:44:21 - [INFO] - Scheduler s·∫Ω ch·∫°y trong 3500 b∆∞·ªõc (350 b∆∞·ªõc/epoch)\n",
      "2025-10-16 21:44:21 - [INFO] - Warmup steps: 350\n",
      "2025-10-16 21:44:21 - [INFO] - S·ª≠ d·ª•ng Class Weights & Label smoothing cho h√†m loss.\n",
      "2025-10-16 21:44:21 - [INFO] - Scheduler s·∫Ω ch·∫°y trong 3500 b∆∞·ªõc (350 b∆∞·ªõc/epoch)\n",
      "2025-10-16 21:44:21 - [INFO] - Warmup steps: 350\n",
      "2025-10-16 21:44:21 - [INFO] - S·ª≠ d·ª•ng Class Weights & Label smoothing cho h√†m loss.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"B∆∞·ªõc 4: Thi·∫øt l·∫≠p optimizer, scheduler v√† loss function...\")\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=cfg.LEARNING_RATE,\n",
    "    weight_decay=cfg.WEIGHT_DECAY,\n",
    "    eps=cfg.EPSILON,\n",
    ")\n",
    "\n",
    "gradient_accumulation_steps = max(1, cfg.GRADIENT_ACCUMULATION_STEPS)\n",
    "num_update_steps_per_epoch = math.ceil(len(train_loader) / gradient_accumulation_steps)\n",
    "num_training_steps = num_update_steps_per_epoch * cfg.EPOCHS\n",
    "logger.info(\n",
    "    f\"Scheduler s·∫Ω ch·∫°y trong {num_training_steps} b∆∞·ªõc ({num_update_steps_per_epoch} b∆∞·ªõc/epoch)\"\n",
    ")\n",
    "\n",
    "warmup_steps = max(1, int(cfg.TOTAL_STEP_SCALE * num_training_steps))\n",
    "scheduler = get_scheduler(\n",
    "    cfg.SCHEDULER_TYPE,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "logger.info(f\"Warmup steps: {warmup_steps}\")\n",
    "\n",
    "class_weights_tensor = torch.tensor(cfg.CLASS_WEIGHTS, dtype=torch.float).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(\n",
    "    weight=class_weights_tensor, label_smoothing=cfg.LABEL_SMOOTHING\n",
    ").to(device)\n",
    "logger.info(\"S·ª≠ d·ª•ng Class Weights & Label smoothing cho h√†m loss.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5a7d7",
   "metadata": {},
   "source": [
    "# ==============================================================================\n",
    "# 5. V√≤ng l·∫∑p Hu·∫•n luy·ªán\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "275d4c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:44:21 - [INFO] - B∆∞·ªõc 5: B·∫Øt ƒë·∫ßu v√≤ng l·∫∑p hu·∫•n luy·ªán...\n",
      "2025-10-16 21:44:21 - [INFO] - --- Epoch 1/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d895f33af1a04f2fad2af45cfa3b5a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:52:11 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 1.0986\n",
      "2025-10-16 21:52:11 - [INFO] - Current Learning Rate: 8.00e-06\n",
      "2025-10-16 21:52:11 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627ca531e7f847f8811c20a4363ef526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 21:52:49 - [INFO] - Validation Loss: 1.0986\n",
      "2025-10-16 21:52:49 - [INFO] - Validation Accuracy: 0.3500\n",
      "2025-10-16 21:52:49 - [INFO] - Validation Macro-F1: 0.1728\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2025-10-16 21:52:49 - [INFO] - Classification Report tr√™n t·∫≠p validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   intrinsic     0.3500    1.0000    0.5185       490\n",
      "   extrinsic     0.0000    0.0000    0.0000       461\n",
      "          no     0.0000    0.0000    0.0000       449\n",
      "\n",
      "    accuracy                         0.3500      1400\n",
      "   macro avg     0.1167    0.3333    0.1728      1400\n",
      "weighted avg     0.1225    0.3500    0.1815      1400\n",
      "\n",
      "2025-10-16 21:52:49 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/CafeBERT-tuned'...\n",
      "2025-10-16 21:52:51 - [INFO] - L∆∞u model th√†nh c√¥ng.\n",
      "2025-10-16 21:52:51 - [INFO] - --- Epoch 2/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1987251818424908929600e6566b0ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 22:00:49 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 1.0986\n",
      "2025-10-16 22:00:49 - [INFO] - Current Learning Rate: 7.76e-06\n",
      "2025-10-16 22:00:49 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4e76b63a67475fb124334af23772de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 22:01:26 - [INFO] - Validation Loss: 1.0986\n",
      "2025-10-16 22:01:26 - [INFO] - Validation Accuracy: 0.3500\n",
      "2025-10-16 22:01:26 - [INFO] - Validation Macro-F1: 0.1728\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2025-10-16 22:01:26 - [INFO] - Classification Report tr√™n t·∫≠p validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   intrinsic     0.3500    1.0000    0.5185       490\n",
      "   extrinsic     0.0000    0.0000    0.0000       461\n",
      "          no     0.0000    0.0000    0.0000       449\n",
      "\n",
      "    accuracy                         0.3500      1400\n",
      "   macro avg     0.1167    0.3333    0.1728      1400\n",
      "weighted avg     0.1225    0.3500    0.1815      1400\n",
      "\n",
      "2025-10-16 22:01:26 - [WARNING] - Macro-F1 kh√¥ng c·∫£i thi·ªán. Patience: 1/2\n",
      "2025-10-16 22:01:26 - [INFO] - --- Epoch 3/10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1079a751480481db6c7806c7f1d3062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/5600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 22:09:33 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 1.0986\n",
      "2025-10-16 22:09:33 - [INFO] - Current Learning Rate: 7.06e-06\n",
      "2025-10-16 22:09:33 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5454011b85144e5d871b2c3e7f7b7e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 22:10:11 - [INFO] - Validation Loss: 1.0986\n",
      "2025-10-16 22:10:11 - [INFO] - Validation Accuracy: 0.3500\n",
      "2025-10-16 22:10:11 - [INFO] - Validation Macro-F1: 0.1728\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2025-10-16 22:10:11 - [INFO] - Classification Report tr√™n t·∫≠p validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   intrinsic     0.3500    1.0000    0.5185       490\n",
      "   extrinsic     0.0000    0.0000    0.0000       461\n",
      "          no     0.0000    0.0000    0.0000       449\n",
      "\n",
      "    accuracy                         0.3500      1400\n",
      "   macro avg     0.1167    0.3333    0.1728      1400\n",
      "weighted avg     0.1225    0.3500    0.1815      1400\n",
      "\n",
      "2025-10-16 22:10:11 - [WARNING] - Macro-F1 kh√¥ng c·∫£i thi·ªán. Patience: 2/2\n",
      "2025-10-16 22:10:11 - [INFO] - Early stopping! D·ª´ng hu·∫•n luy·ªán.\n",
      "2025-10-16 22:10:11 - [INFO] - üèÅ Qu√° tr√¨nh hu·∫•n luy·ªán ho√†n t·∫•t.\n",
      "2025-10-16 22:10:11 - [INFO] - Model t·ªët nh·∫•t v·ªõi Macro-F1 = 0.1728 ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i '/home/guest/Projects/CS221/models/CafeBERT-tuned'\n",
      "2025-10-16 22:10:11 - [INFO] - Validation Accuracy: 0.3500\n",
      "2025-10-16 22:10:11 - [INFO] - Validation Macro-F1: 0.1728\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/guest/.conda/envs/cs221/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "2025-10-16 22:10:11 - [INFO] - Classification Report tr√™n t·∫≠p validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   intrinsic     0.3500    1.0000    0.5185       490\n",
      "   extrinsic     0.0000    0.0000    0.0000       461\n",
      "          no     0.0000    0.0000    0.0000       449\n",
      "\n",
      "    accuracy                         0.3500      1400\n",
      "   macro avg     0.1167    0.3333    0.1728      1400\n",
      "weighted avg     0.1225    0.3500    0.1815      1400\n",
      "\n",
      "2025-10-16 22:10:11 - [WARNING] - Macro-F1 kh√¥ng c·∫£i thi·ªán. Patience: 2/2\n",
      "2025-10-16 22:10:11 - [INFO] - Early stopping! D·ª´ng hu·∫•n luy·ªán.\n",
      "2025-10-16 22:10:11 - [INFO] - üèÅ Qu√° tr√¨nh hu·∫•n luy·ªán ho√†n t·∫•t.\n",
      "2025-10-16 22:10:11 - [INFO] - Model t·ªët nh·∫•t v·ªõi Macro-F1 = 0.1728 ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i '/home/guest/Projects/CS221/models/CafeBERT-tuned'\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"B∆∞·ªõc 5: B·∫Øt ƒë·∫ßu v√≤ng l·∫∑p hu·∫•n luy·ªán...\")\n",
    "best_macro_f1 = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(cfg.EPOCHS):\n",
    "    logger.info(f\"--- Epoch {epoch + 1}/{cfg.EPOCHS} ---\")\n",
    "\n",
    "    avg_train_loss = train_one_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        device,\n",
    "        tokenizer=tokenizer,\n",
    "        verbalizer_ids_tensor=verbalizer_ids_tensor,\n",
    "        label_map=original_label_to_verbalizer_idx,\n",
    "        epoch=epoch + 1,\n",
    "        total_epochs=cfg.EPOCHS,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    )\n",
    "    logger.info(f\"Loss trung b√¨nh tr√™n t·∫≠p train: {avg_train_loss:.4f}\")\n",
    "    logger.info(f\"Current Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    logger.info(\"B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...\")\n",
    "    val_labels, val_preds, avg_val_loss = evaluate(\n",
    "        model,\n",
    "        val_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        tokenizer=tokenizer,\n",
    "        verbalizer_ids_tensor=verbalizer_ids_tensor,\n",
    "        label_map=original_label_to_verbalizer_idx,\n",
    "        id2label_map=verbalizer_idx_to_original_label,\n",
    "    )\n",
    "\n",
    "    accuracy = accuracy_score(val_labels, val_preds)\n",
    "    macro_f1 = f1_score(val_labels, val_preds, average=\"macro\")\n",
    "\n",
    "    logger.info(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    logger.info(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    logger.info(f\"Validation Macro-F1: {macro_f1:.4f}\")\n",
    "\n",
    "    report = classification_report(\n",
    "        val_labels,\n",
    "        val_preds,\n",
    "        target_names=[cfg.ID2LABEL[i] for i in range(len(cfg.LABEL_MAP))],\n",
    "        digits=4,\n",
    "    )\n",
    "    logger.info(f\"Classification Report tr√™n t·∫≠p validation:\\n{report}\")\n",
    "\n",
    "    if macro_f1 > best_macro_f1:\n",
    "        best_macro_f1 = macro_f1\n",
    "        patience_counter = 0\n",
    "        logger.info(\n",
    "            f\"üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '{cfg.MODEL_OUTPUT_DIR}'...\"\n",
    "        )\n",
    "        os.makedirs(cfg.MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "        model.save_pretrained(cfg.MODEL_OUTPUT_DIR)\n",
    "        tokenizer.save_pretrained(cfg.MODEL_OUTPUT_DIR)\n",
    "        logger.info(\"L∆∞u model th√†nh c√¥ng.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        logger.warning(\n",
    "            f\"Macro-F1 kh√¥ng c·∫£i thi·ªán. Patience: {patience_counter}/{cfg.PATIENCE_LIMIT}\"\n",
    "        )\n",
    "        if patience_counter >= cfg.PATIENCE_LIMIT:\n",
    "            logger.info(\"Early stopping! D·ª´ng hu·∫•n luy·ªán.\")\n",
    "            break\n",
    "\n",
    "logger.info(\"üèÅ Qu√° tr√¨nh hu·∫•n luy·ªán ho√†n t·∫•t.\")\n",
    "logger.info(\n",
    "    f\"Model t·ªët nh·∫•t v·ªõi Macro-F1 = {best_macro_f1:.4f} ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i '{cfg.MODEL_OUTPUT_DIR}'\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f5a5e",
   "metadata": {},
   "source": [
    "# Ph√¢n ph·ªëi k·∫øt qu·∫£ ƒë√∫ng/sai theo t·ª´ng l·ªõp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72fc9859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 22:10:11 - [INFO] - Ph√¢n ph·ªëi k·∫øt qu·∫£ tr√™n t·ª´ng l·ªõp:\n",
      "  true_label  correct  incorrect  total correct_rate incorrect_rate\n",
      "0  extrinsic        0        461    461        0.00%        100.00%\n",
      "1  intrinsic      490          0    490      100.00%          0.00%\n",
      "2         no        0        449    449        0.00%        100.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B·∫£ng ph√¢n ph·ªëi k·∫øt qu·∫£ tr√™n t·ª´ng l·ªõp:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>correct</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>total</th>\n",
       "      <th>correct_rate</th>\n",
       "      <th>incorrect_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>extrinsic</td>\n",
       "      <td>0</td>\n",
       "      <td>461</td>\n",
       "      <td>461</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intrinsic</td>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>449</td>\n",
       "      <td>449</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>100.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  true_label  correct  incorrect  total correct_rate incorrect_rate\n",
       "0  extrinsic        0        461    461        0.00%        100.00%\n",
       "1  intrinsic      490          0    490      100.00%          0.00%\n",
       "2         no        0        449    449        0.00%        100.00%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_label_names = [cfg.ID2LABEL[label_id] for label_id in val_labels]\n",
    "pred_label_names = [cfg.ID2LABEL[pred_id] for pred_id in val_preds]\n",
    "evaluation_df = pd.DataFrame(\n",
    "    {\n",
    "        \"true_label\": val_label_names,\n",
    "        \"predicted_label\": pred_label_names,\n",
    "    }\n",
    ")\n",
    "evaluation_df[\"status\"] = evaluation_df.apply(\n",
    "    lambda row: (\n",
    "        \"correct\" if row[\"true_label\"] == row[\"predicted_label\"] else \"incorrect\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "distribution_table = (\n",
    "    evaluation_df.groupby([\"true_label\", \"status\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .rename_axis(None, axis=1)\n",
    "    .reset_index()\n",
    "    .sort_values(\"true_label\")\n",
    ")\n",
    "\n",
    "# 1. Th√™m c·ªôt 'total' b·∫±ng c√°ch c·ªông c·ªôt 'correct' v√† 'incorrect'\n",
    "distribution_table[\"total\"] = (\n",
    "    distribution_table[\"correct\"] + distribution_table[\"incorrect\"]\n",
    ")\n",
    "\n",
    "# 2. Th√™m c·ªôt t·ªâ l·ªá ƒë√∫ng (correct_rate)\n",
    "distribution_table[\"correct_rate\"] = (\n",
    "    distribution_table[\"correct\"] / distribution_table[\"total\"]\n",
    ")\n",
    "\n",
    "# 3. Th√™m c·ªôt t·ªâ l·ªá sai (incorrect_rate)\n",
    "distribution_table[\"incorrect_rate\"] = (\n",
    "    distribution_table[\"incorrect\"] / distribution_table[\"total\"]\n",
    ")\n",
    "\n",
    "# (T√πy ch·ªçn) Format c√°c c·ªôt t·ªâ l·ªá th√†nh d·∫°ng ph·∫ßn trƒÉm cho d·ªÖ ƒë·ªçc\n",
    "distribution_table[\"correct_rate\"] = distribution_table[\"correct_rate\"].map(\n",
    "    \"{:.2%}\".format\n",
    ")\n",
    "distribution_table[\"incorrect_rate\"] = distribution_table[\"incorrect_rate\"].map(\n",
    "    \"{:.2%}\".format\n",
    ")\n",
    "\n",
    "# In ra b·∫£ng k·∫øt qu·∫£\n",
    "logger.info(f\"Ph√¢n ph·ªëi k·∫øt qu·∫£ tr√™n t·ª´ng l·ªõp:\\n{distribution_table.to_string()}\")\n",
    "\n",
    "# Trong notebook, d√πng display() s·∫Ω cho b·∫£ng ƒë·∫πp h∆°n\n",
    "print(\"B·∫£ng ph√¢n ph·ªëi k·∫øt qu·∫£ tr√™n t·ª´ng l·ªõp:\")\n",
    "display(distribution_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
