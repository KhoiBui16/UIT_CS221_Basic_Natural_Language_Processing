2025-10-17 14:07:11 - [INFO] - Logger cho 'FacebookAI_xlm-roberta-large-training' ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o. File log: logs/FacebookAI_xlm-roberta-large-training/2025-10-17_14-07-11.log
2025-10-17 14:07:11 - [INFO] - Logger initialized for FacebookAI/xlm-roberta-large
2025-10-17 14:07:11 - [INFO] - ============================================================
2025-10-17 14:07:11 - [INFO] - üöÄ STARTING TRAINING SESSION
2025-10-17 14:07:11 - [INFO] - ============================================================
2025-10-17 14:07:11 - [INFO] - ROOT_DIR: /home/guest/Projects/CS221
2025-10-17 14:07:11 - [INFO] - DATA_DIR: /home/guest/Projects/CS221/data
2025-10-17 14:07:11 - [INFO] - TRAIN_FILE: /home/guest/Projects/CS221/data/vihallu-train.csv
2025-10-17 14:07:11 - [INFO] - TEST_FILE: /home/guest/Projects/CS221/data/vihallu-public-test.csv
2025-10-17 14:07:11 - [INFO] - SUBMISSION_DIR: /home/guest/Projects/CS221/submission
2025-10-17 14:07:11 - [INFO] - SUBMISSION_CSV: submit.csv
2025-10-17 14:07:11 - [INFO] - SUBMISSION_ZIP: submit.zip
2025-10-17 14:07:11 - [INFO] - MODEL_NAME: FacebookAI/xlm-roberta-large
2025-10-17 14:07:11 - [INFO] - MODEL_OUTPUT_DIR: /home/guest/Projects/CS221/models/xlm-roberta-large-tuned
2025-10-17 14:07:11 - [INFO] - MAX_LENGTH: 512
2025-10-17 14:07:11 - [INFO] - RANDOM_STATE: 42
2025-10-17 14:07:11 - [INFO] - EPOCHS: 10
2025-10-17 14:07:11 - [INFO] - BATCH_SIZE: 4
2025-10-17 14:07:11 - [INFO] - GRADIENT_ACCUMULATION_STEPS: 4
2025-10-17 14:07:11 - [INFO] - SCHEDULER_TYPE: constant_with_warmup
2025-10-17 14:07:11 - [INFO] - LEARNING_RATE: 8e-06
2025-10-17 14:07:11 - [INFO] - WEIGHT_DECAY: 0.01
2025-10-17 14:07:11 - [INFO] - NUM_CYCLES: 3
2025-10-17 14:07:11 - [INFO] - CLASSIFIER_DROPOUT: 0.1
2025-10-17 14:07:11 - [INFO] - LABEL_SMOOTHING: 0.05
2025-10-17 14:07:11 - [INFO] - TOTAL_STEP_SCALE: 0.1
2025-10-17 14:07:11 - [INFO] - EPSILON: 1e-08
2025-10-17 14:07:11 - [INFO] - PATIENCE_LIMIT: 3
2025-10-17 14:07:11 - [INFO] - VALIDATION_SPLIT_SIZE: 0.2
2025-10-17 14:07:11 - [INFO] - LABEL_MAP: {'no': 0, 'extrinsic': 1, 'intrinsic': 2}
2025-10-17 14:07:11 - [INFO] - ID2LABEL: {0: 'no', 1: 'extrinsic', 2: 'intrinsic'}
2025-10-17 14:07:11 - [INFO] - CLASS_WEIGHTS: [1.0393466963622866, 1.0114145354717525, 0.9531590413943355]
2025-10-17 14:07:11 - [INFO] - ============================================================
2025-10-17 14:07:14 - [INFO] - B·∫Øt ƒë·∫ßu pipeline hu·∫•n luy·ªán.
2025-10-17 14:07:14 - [INFO] - B∆∞·ªõc 1: Chu·∫©n b·ªã d·ªØ li·ªáu...
2025-10-17 14:07:14 - [INFO] - Chia d·ªØ li·ªáu: 5600 m·∫´u train, 1400 m·∫´u validation.
2025-10-17 14:07:14 - [INFO] - B∆∞·ªõc 2: T·∫£i model 'FacebookAI/xlm-roberta-large' v√† tokenizer...
2025-10-17 14:07:17 - [INFO] - Ph√¢n t√≠ch ki·∫øn tr√∫c m√¥ h√¨nh b·∫±ng torchinfo...
2025-10-17 14:07:20 - [INFO] - Ki·∫øn tr√∫c chi ti·∫øt c·ªßa m√¥ h√¨nh:
=====================================================================================================================================================================
Layer (type:depth-idx)                                            Input Shape               Output Shape              Param #                   Mult-Adds
=====================================================================================================================================================================
XLMRobertaForSequenceClassification                               --                        [4, 3]                    --                        --
‚îú‚îÄXLMRobertaModel: 1-1                                            [4, 512]                  [4, 512, 1024]            --                        --
‚îÇ    ‚îî‚îÄXLMRobertaEmbeddings: 2-1                                  --                        [4, 512, 1024]            --                        --
‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-1                                        [4, 512]                  [4, 512, 1024]            256,002,048               1,024,008,192
‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-2                                        [4, 512]                  [4, 512, 1024]            1,024                     4,096
‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-3                                        [4, 512]                  [4, 512, 1024]            526,336                   2,105,344
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-4                                        [4, 512, 1024]            [4, 512, 1024]            2,048                     8,192
‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-5                                          [4, 512, 1024]            [4, 512, 1024]            --                        --
‚îÇ    ‚îî‚îÄXLMRobertaEncoder: 2-2                                     [4, 512, 1024]            [4, 512, 1024]            --                        --
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6                                       --                        --                        302,309,376               --
‚îú‚îÄXLMRobertaClassificationHead: 1-2                               [4, 512, 1024]            [4, 3]                    --                        --
‚îÇ    ‚îî‚îÄDropout: 2-3                                               [4, 1024]                 [4, 1024]                 --                        --
‚îÇ    ‚îî‚îÄLinear: 2-4                                                [4, 1024]                 [4, 1024]                 1,049,600                 4,198,400
‚îÇ    ‚îî‚îÄDropout: 2-5                                               [4, 1024]                 [4, 1024]                 --                        --
‚îÇ    ‚îî‚îÄLinear: 2-6                                                [4, 1024]                 [4, 3]                    3,075                     12,300
=====================================================================================================================================================================
Total params: 559,893,507
Trainable params: 559,893,507
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 2.24
=====================================================================================================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 4496.33
Params size (MB): 2239.57
Estimated Total Size (MB): 6735.92
=====================================================================================================================================================================
2025-10-17 14:07:20 - [INFO] - B∆∞·ªõc 3: T·∫°o Dataset v√† DataLoader...
2025-10-17 14:07:20 - [INFO] - ‚úÖ T·∫°o DataLoader th√†nh c√¥ng v·ªõi DataCollatorWithPadding chu·∫©n!
2025-10-17 14:07:20 - [INFO] - Gradient accumulation steps: 4 | Effective batch size: 16
2025-10-17 14:07:20 - [INFO] - B∆∞·ªõc 4: Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng hu·∫•n luy·ªán v√† ki·∫øn tr√∫c model...
2025-10-17 14:07:20 - [INFO] - S·ª≠ d·ª•ng thi·∫øt b·ªã: cuda
2025-10-17 14:07:20 - [INFO] - ‚úÖ T√¨m th·∫•y 1 GPU(s).
2025-10-17 14:07:20 - [INFO] - ‚úÖ ƒêang s·ª≠ d·ª•ng GPU: NVIDIA GeForce RTX 5070 Ti
2025-10-17 14:07:20 - [INFO] - Ki·∫øn tr√∫c c·ªßa m√¥ h√¨nh:
XLMRobertaForSequenceClassification(
  (roberta): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 1024, padding_idx=1)
      (position_embeddings): Embedding(514, 1024, padding_idx=1)
      (token_type_embeddings): Embedding(1, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-23): 24 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (classifier): XLMRobertaClassificationHead(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (out_proj): Linear(in_features=1024, out_features=3, bias=True)
  )
)
2025-10-17 14:07:21 - [INFO] - Scheduler will run for 3500 total steps (350 per epoch)
2025-10-17 14:07:21 - [INFO] - S·ª≠ d·ª•ng scheduler chung: constant_with_warmup
2025-10-17 14:07:21 - [INFO] - Warmup steps: 350
2025-10-17 14:07:21 - [INFO] - S·ª≠ d·ª•ng Class Weights & Label smoothing cho h√†m loss.
2025-10-17 14:07:21 - [INFO] - --- Epoch 1/10 ---
2025-10-17 14:11:45 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 1.1033
2025-10-17 14:11:45 - [INFO] - Current Learning Rate: 8.00e-06
2025-10-17 14:11:45 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 14:12:06 - [INFO] - Validation Loss: 1.0034
2025-10-17 14:12:06 - [INFO] - Validation Accuracy: 0.3943
2025-10-17 14:12:06 - [INFO] - Validation Macro-F1: 0.2649
2025-10-17 14:12:06 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.8625    0.1537    0.2609       449
   extrinsic     0.0000    0.0000    0.0000       461
   intrinsic     0.3659    0.9857    0.5337       490

    accuracy                         0.3943      1400
   macro avg     0.4095    0.3798    0.2649      1400
weighted avg     0.4047    0.3943    0.2705      1400

2025-10-17 14:12:06 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/xlm-roberta-large-tuned'...
2025-10-17 14:12:08 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 14:12:08 - [INFO] - --- Epoch 2/10 ---
2025-10-17 14:16:22 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.8490
2025-10-17 14:16:22 - [INFO] - Current Learning Rate: 8.00e-06
2025-10-17 14:16:22 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 14:16:43 - [INFO] - Validation Loss: 0.8177
2025-10-17 14:16:43 - [INFO] - Validation Accuracy: 0.7186
2025-10-17 14:16:43 - [INFO] - Validation Macro-F1: 0.7214
2025-10-17 14:16:43 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.8184    0.6526    0.7261       449
   extrinsic     0.7701    0.7484    0.7591       461
   intrinsic     0.6195    0.7510    0.6790       490

    accuracy                         0.7186      1400
   macro avg     0.7360    0.7173    0.7214      1400
weighted avg     0.7329    0.7186    0.7205      1400

2025-10-17 14:16:43 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/xlm-roberta-large-tuned'...
2025-10-17 14:16:45 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 14:16:45 - [INFO] - --- Epoch 3/10 ---
2025-10-17 14:21:07 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.6871
2025-10-17 14:21:07 - [INFO] - Current Learning Rate: 8.00e-06
2025-10-17 14:21:07 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 14:21:28 - [INFO] - Validation Loss: 0.6540
2025-10-17 14:21:28 - [INFO] - Validation Accuracy: 0.7943
2025-10-17 14:21:28 - [INFO] - Validation Macro-F1: 0.7942
2025-10-17 14:21:28 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.7932    0.8886    0.8382       449
   extrinsic     0.8277    0.7397    0.7812       461
   intrinsic     0.7670    0.7592    0.7631       490

    accuracy                         0.7943      1400
   macro avg     0.7960    0.7958    0.7942      1400
weighted avg     0.7954    0.7943    0.7932      1400

2025-10-17 14:21:28 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/xlm-roberta-large-tuned'...
2025-10-17 14:21:30 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 14:21:30 - [INFO] - --- Epoch 4/10 ---
2025-10-17 14:25:52 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.6063
2025-10-17 14:25:52 - [INFO] - Current Learning Rate: 8.00e-06
2025-10-17 14:25:52 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 14:26:12 - [INFO] - Validation Loss: 0.7118
2025-10-17 14:26:12 - [INFO] - Validation Accuracy: 0.7679
2025-10-17 14:26:12 - [INFO] - Validation Macro-F1: 0.7695
2025-10-17 14:26:12 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.8357    0.7706    0.8019       449
   extrinsic     0.8170    0.7072    0.7581       461
   intrinsic     0.6865    0.8224    0.7484       490

    accuracy                         0.7679      1400
   macro avg     0.7798    0.7667    0.7695      1400
weighted avg     0.7774    0.7679    0.7687      1400

2025-10-17 14:26:12 - [WARNING] - Macro-F1 kh√¥ng c·∫£i thi·ªán. Patience: 1/3
2025-10-17 14:26:12 - [INFO] - --- Epoch 5/10 ---
2025-10-17 14:30:23 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.5473
2025-10-17 14:30:23 - [INFO] - Current Learning Rate: 8.00e-06
2025-10-17 14:30:23 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 14:30:44 - [INFO] - Validation Loss: 0.7077
2025-10-17 14:30:44 - [INFO] - Validation Accuracy: 0.7836
2025-10-17 14:30:44 - [INFO] - Validation Macro-F1: 0.7835
2025-10-17 14:30:44 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.8012    0.8708    0.8346       449
   extrinsic     0.8103    0.7137    0.7589       461
   intrinsic     0.7451    0.7694    0.7570       490

    accuracy                         0.7836      1400
   macro avg     0.7855    0.7846    0.7835      1400
weighted avg     0.7846    0.7836    0.7825      1400

2025-10-17 14:30:44 - [WARNING] - Macro-F1 kh√¥ng c·∫£i thi·ªán. Patience: 2/3
2025-10-17 14:30:44 - [INFO] - --- Epoch 6/10 ---
2025-10-17 14:35:03 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.4769
2025-10-17 14:35:03 - [INFO] - Current Learning Rate: 8.00e-06
2025-10-17 14:35:03 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 14:35:23 - [INFO] - Validation Loss: 0.7305
2025-10-17 14:35:23 - [INFO] - Validation Accuracy: 0.7786
2025-10-17 14:35:23 - [INFO] - Validation Macro-F1: 0.7790
2025-10-17 14:35:23 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.8084    0.8552    0.8312       449
   extrinsic     0.7847    0.7354    0.7592       461
   intrinsic     0.7444    0.7490    0.7467       490

    accuracy                         0.7786      1400
   macro avg     0.7792    0.7799    0.7790      1400
weighted avg     0.7782    0.7786    0.7779      1400

2025-10-17 14:35:23 - [WARNING] - Macro-F1 kh√¥ng c·∫£i thi·ªán. Patience: 3/3
2025-10-17 14:35:23 - [INFO] - Early stopping! D·ª´ng hu·∫•n luy·ªán.
2025-10-17 14:35:23 - [INFO] - üèÅ Qu√° tr√¨nh hu·∫•n luy·ªán ho√†n t·∫•t.
2025-10-17 14:35:23 - [INFO] - Model t·ªët nh·∫•t v·ªõi Macro-F1 = 0.7942 ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i '/home/guest/Projects/CS221/models/xlm-roberta-large-tuned'
2025-10-17 14:35:23 - [INFO] - Ph√¢n ph·ªëi k·∫øt qu·∫£ tr√™n t·ª´ng l·ªõp:
  true_label  correct  incorrect  total correct_rate incorrect_rate
0  extrinsic      339        122    461       73.54%         26.46%
1  intrinsic      367        123    490       74.90%         25.10%
2         no      384         65    449       85.52%         14.48%
