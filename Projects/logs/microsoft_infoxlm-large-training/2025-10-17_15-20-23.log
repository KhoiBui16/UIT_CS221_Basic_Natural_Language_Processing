2025-10-17 15:20:23 - [INFO] - Logger cho 'microsoft_infoxlm-large-training' ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o. File log: logs/microsoft_infoxlm-large-training/2025-10-17_15-20-23.log
2025-10-17 15:20:23 - [INFO] - Logger initialized for microsoft/infoxlm-large
2025-10-17 15:20:23 - [INFO] - ============================================================
2025-10-17 15:20:23 - [INFO] - üöÄ STARTING TRAINING SESSION
2025-10-17 15:20:23 - [INFO] - ============================================================
2025-10-17 15:20:23 - [INFO] - ROOT_DIR: /home/guest/Projects/CS221
2025-10-17 15:20:23 - [INFO] - DATA_DIR: /home/guest/Projects/CS221/data
2025-10-17 15:20:23 - [INFO] - TRAIN_FILE: /home/guest/Projects/CS221/data/vihallu-train.csv
2025-10-17 15:20:23 - [INFO] - TEST_FILE: /home/guest/Projects/CS221/data/vihallu-public-test.csv
2025-10-17 15:20:23 - [INFO] - SUBMISSION_DIR: /home/guest/Projects/CS221/submission
2025-10-17 15:20:23 - [INFO] - SUBMISSION_CSV: submit.csv
2025-10-17 15:20:23 - [INFO] - SUBMISSION_ZIP: submit.zip
2025-10-17 15:20:23 - [INFO] - MODEL_NAME: microsoft/infoxlm-large
2025-10-17 15:20:23 - [INFO] - MODEL_OUTPUT_DIR: /home/guest/Projects/CS221/models/infoxlm-large-tuned
2025-10-17 15:20:23 - [INFO] - MAX_LENGTH: 512
2025-10-17 15:20:23 - [INFO] - RANDOM_STATE: 42
2025-10-17 15:20:23 - [INFO] - EPOCHS: 10
2025-10-17 15:20:23 - [INFO] - BATCH_SIZE: 4
2025-10-17 15:20:23 - [INFO] - GRADIENT_ACCUMULATION_STEPS: 4
2025-10-17 15:20:23 - [INFO] - SCHEDULER_TYPE: constant_with_warmup
2025-10-17 15:20:23 - [INFO] - LEARNING_RATE: 1e-05
2025-10-17 15:20:23 - [INFO] - WEIGHT_DECAY: 0.01
2025-10-17 15:20:23 - [INFO] - NUM_CYCLES: 3
2025-10-17 15:20:23 - [INFO] - CLASSIFIER_DROPOUT: 0.1
2025-10-17 15:20:23 - [INFO] - LABEL_SMOOTHING: 0.05
2025-10-17 15:20:23 - [INFO] - TOTAL_STEP_SCALE: 0.1
2025-10-17 15:20:23 - [INFO] - EPSILON: 1e-08
2025-10-17 15:20:23 - [INFO] - PATIENCE_LIMIT: 3
2025-10-17 15:20:23 - [INFO] - VALIDATION_SPLIT_SIZE: 0.2
2025-10-17 15:20:23 - [INFO] - LABEL_MAP: {'no': 0, 'extrinsic': 1, 'intrinsic': 2}
2025-10-17 15:20:23 - [INFO] - ID2LABEL: {0: 'no', 1: 'extrinsic', 2: 'intrinsic'}
2025-10-17 15:20:23 - [INFO] - CLASS_WEIGHTS: [1.0393466963622866, 1.0114145354717525, 0.9531590413943355]
2025-10-17 15:20:23 - [INFO] - ============================================================
2025-10-17 15:20:26 - [INFO] - B·∫Øt ƒë·∫ßu pipeline hu·∫•n luy·ªán.
2025-10-17 15:20:26 - [INFO] - B∆∞·ªõc 1: Chu·∫©n b·ªã d·ªØ li·ªáu...
2025-10-17 15:20:26 - [INFO] - Chia d·ªØ li·ªáu: 5600 m·∫´u train, 1400 m·∫´u validation.
2025-10-17 15:20:26 - [INFO] - B∆∞·ªõc 2: T·∫£i model 'microsoft/infoxlm-large' v√† tokenizer...
2025-10-17 15:20:31 - [INFO] - Ph√¢n t√≠ch ki·∫øn tr√∫c m√¥ h√¨nh b·∫±ng torchinfo...
2025-10-17 15:20:32 - [INFO] - Ki·∫øn tr√∫c chi ti·∫øt c·ªßa m√¥ h√¨nh:
=====================================================================================================================================================================
Layer (type:depth-idx)                                            Input Shape               Output Shape              Param #                   Mult-Adds
=====================================================================================================================================================================
XLMRobertaForSequenceClassification                               --                        [4, 3]                    --                        --
‚îú‚îÄXLMRobertaModel: 1-1                                            [4, 512]                  [4, 512, 1024]            --                        --
‚îÇ    ‚îî‚îÄXLMRobertaEmbeddings: 2-1                                  --                        [4, 512, 1024]            --                        --
‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-1                                        [4, 512]                  [4, 512, 1024]            256,002,048               1,024,008,192
‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-2                                        [4, 512]                  [4, 512, 1024]            1,024                     4,096
‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-3                                        [4, 512]                  [4, 512, 1024]            526,336                   2,105,344
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-4                                        [4, 512, 1024]            [4, 512, 1024]            2,048                     8,192
‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-5                                          [4, 512, 1024]            [4, 512, 1024]            --                        --
‚îÇ    ‚îî‚îÄXLMRobertaEncoder: 2-2                                     [4, 512, 1024]            [4, 512, 1024]            --                        --
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6                                       --                        --                        302,309,376               --
‚îú‚îÄXLMRobertaClassificationHead: 1-2                               [4, 512, 1024]            [4, 3]                    --                        --
‚îÇ    ‚îî‚îÄDropout: 2-3                                               [4, 1024]                 [4, 1024]                 --                        --
‚îÇ    ‚îî‚îÄLinear: 2-4                                                [4, 1024]                 [4, 1024]                 1,049,600                 4,198,400
‚îÇ    ‚îî‚îÄDropout: 2-5                                               [4, 1024]                 [4, 1024]                 --                        --
‚îÇ    ‚îî‚îÄLinear: 2-6                                                [4, 1024]                 [4, 3]                    3,075                     12,300
=====================================================================================================================================================================
Total params: 559,893,507
Trainable params: 559,893,507
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 2.24
=====================================================================================================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 4496.33
Params size (MB): 2239.57
Estimated Total Size (MB): 6735.92
=====================================================================================================================================================================
2025-10-17 15:20:32 - [INFO] - B∆∞·ªõc 3: T·∫°o Dataset v√† DataLoader...
2025-10-17 15:20:32 - [INFO] - ‚úÖ T·∫°o DataLoader th√†nh c√¥ng v·ªõi DataCollatorWithPadding chu·∫©n!
2025-10-17 15:20:32 - [INFO] - Gradient accumulation steps: 4 | Effective batch size: 16
2025-10-17 15:20:32 - [INFO] - B∆∞·ªõc 4: Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng hu·∫•n luy·ªán v√† ki·∫øn tr√∫c model...
2025-10-17 15:20:32 - [INFO] - S·ª≠ d·ª•ng thi·∫øt b·ªã: cuda
2025-10-17 15:20:32 - [INFO] - ‚úÖ T√¨m th·∫•y 1 GPU(s).
2025-10-17 15:20:32 - [INFO] - ‚úÖ ƒêang s·ª≠ d·ª•ng GPU: NVIDIA GeForce RTX 5070 Ti
2025-10-17 15:20:32 - [INFO] - Ki·∫øn tr√∫c c·ªßa m√¥ h√¨nh:
XLMRobertaForSequenceClassification(
  (roberta): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 1024, padding_idx=1)
      (position_embeddings): Embedding(514, 1024, padding_idx=1)
      (token_type_embeddings): Embedding(1, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-23): 24 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (classifier): XLMRobertaClassificationHead(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (out_proj): Linear(in_features=1024, out_features=3, bias=True)
  )
)
2025-10-17 15:20:33 - [INFO] - Scheduler will run for 3500 total steps (350 per epoch)
2025-10-17 15:20:33 - [INFO] - S·ª≠ d·ª•ng scheduler chung: constant_with_warmup
2025-10-17 15:20:33 - [INFO] - Warmup steps: 350
2025-10-17 15:20:33 - [INFO] - S·ª≠ d·ª•ng Class Weights & Label smoothing cho h√†m loss.
2025-10-17 15:20:33 - [INFO] - --- Epoch 1/10 ---
2025-10-17 15:24:58 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 1.1044
2025-10-17 15:24:58 - [INFO] - Current Learning Rate: 1.00e-05
2025-10-17 15:24:58 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 15:25:19 - [INFO] - Validation Loss: 1.1008
2025-10-17 15:25:19 - [INFO] - Validation Accuracy: 0.3293
2025-10-17 15:25:19 - [INFO] - Validation Macro-F1: 0.1651
2025-10-17 15:25:19 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.0000    0.0000    0.0000       449
   extrinsic     0.3293    1.0000    0.4954       461
   intrinsic     0.0000    0.0000    0.0000       490

    accuracy                         0.3293      1400
   macro avg     0.1098    0.3333    0.1651      1400
weighted avg     0.1084    0.3293    0.1631      1400

2025-10-17 15:25:19 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/infoxlm-large-tuned'...
2025-10-17 15:25:21 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 15:25:21 - [INFO] - --- Epoch 2/10 ---
2025-10-17 15:29:42 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 1.0997
2025-10-17 15:29:42 - [INFO] - Current Learning Rate: 1.00e-05
2025-10-17 15:29:42 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 15:30:03 - [INFO] - Validation Loss: 0.9437
2025-10-17 15:30:03 - [INFO] - Validation Accuracy: 0.5629
2025-10-17 15:30:03 - [INFO] - Validation Macro-F1: 0.5374
2025-10-17 15:30:03 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.5103    0.8797    0.6460       449
   extrinsic     0.7165    0.6139    0.6612       461
   intrinsic     0.4762    0.2245    0.3051       490

    accuracy                         0.5629      1400
   macro avg     0.5677    0.5727    0.5374      1400
weighted avg     0.5663    0.5629    0.5317      1400

2025-10-17 15:30:03 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/infoxlm-large-tuned'...
2025-10-17 15:30:05 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 15:30:05 - [INFO] - --- Epoch 3/10 ---
2025-10-17 15:34:31 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.8378
2025-10-17 15:34:31 - [INFO] - Current Learning Rate: 1.00e-05
2025-10-17 15:34:31 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 15:34:52 - [INFO] - Validation Loss: 0.7083
2025-10-17 15:34:52 - [INFO] - Validation Accuracy: 0.7650
2025-10-17 15:34:52 - [INFO] - Validation Macro-F1: 0.7629
2025-10-17 15:34:52 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.7853    0.8797    0.8298       449
   extrinsic     0.7253    0.8134    0.7669       461
   intrinsic     0.7921    0.6143    0.6920       490

    accuracy                         0.7650      1400
   macro avg     0.7676    0.7692    0.7629      1400
weighted avg     0.7679    0.7650    0.7608      1400

2025-10-17 15:34:52 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/infoxlm-large-tuned'...
2025-10-17 15:34:54 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 15:34:54 - [INFO] - --- Epoch 4/10 ---
2025-10-17 15:39:21 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.7180
2025-10-17 15:39:21 - [INFO] - Current Learning Rate: 1.00e-05
2025-10-17 15:39:21 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 15:39:42 - [INFO] - Validation Loss: 0.6965
2025-10-17 15:39:42 - [INFO] - Validation Accuracy: 0.7671
2025-10-17 15:39:42 - [INFO] - Validation Macro-F1: 0.7670
2025-10-17 15:39:42 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.7987    0.8486    0.8229       449
   extrinsic     0.8720    0.6356    0.7353       461
   intrinsic     0.6814    0.8163    0.7428       490

    accuracy                         0.7671      1400
   macro avg     0.7841    0.7668    0.7670      1400
weighted avg     0.7818    0.7671    0.7660      1400

2025-10-17 15:39:42 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/infoxlm-large-tuned'...
2025-10-17 15:39:44 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 15:39:44 - [INFO] - --- Epoch 5/10 ---
2025-10-17 15:44:07 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.6371
2025-10-17 15:44:07 - [INFO] - Current Learning Rate: 1.00e-05
2025-10-17 15:44:07 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 15:44:28 - [INFO] - Validation Loss: 0.6724
2025-10-17 15:44:28 - [INFO] - Validation Accuracy: 0.7757
2025-10-17 15:44:28 - [INFO] - Validation Macro-F1: 0.7761
2025-10-17 15:44:28 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.7934    0.8552    0.8232       449
   extrinsic     0.8073    0.7180    0.7600       461
   intrinsic     0.7332    0.7571    0.7450       490

    accuracy                         0.7757      1400
   macro avg     0.7780    0.7768    0.7761      1400
weighted avg     0.7769    0.7757    0.7750      1400

2025-10-17 15:44:28 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/infoxlm-large-tuned'...
2025-10-17 15:44:30 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 15:44:30 - [INFO] - --- Epoch 6/10 ---
2025-10-17 15:48:54 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.5327
2025-10-17 15:48:54 - [INFO] - Current Learning Rate: 1.00e-05
2025-10-17 15:48:54 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 15:49:15 - [INFO] - Validation Loss: 0.6802
2025-10-17 15:49:15 - [INFO] - Validation Accuracy: 0.7800
2025-10-17 15:49:15 - [INFO] - Validation Macro-F1: 0.7812
2025-10-17 15:49:15 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.8203    0.8441    0.8321       449
   extrinsic     0.8082    0.7310    0.7677       461
   intrinsic     0.7217    0.7673    0.7438       490

    accuracy                         0.7800      1400
   macro avg     0.7834    0.7808    0.7812      1400
weighted avg     0.7818    0.7800    0.7800      1400

2025-10-17 15:49:15 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/infoxlm-large-tuned'...
2025-10-17 15:49:17 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 15:49:17 - [INFO] - --- Epoch 7/10 ---
2025-10-17 15:53:41 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.4854
2025-10-17 15:53:41 - [INFO] - Current Learning Rate: 1.00e-05
2025-10-17 15:53:41 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 15:54:01 - [INFO] - Validation Loss: 0.7247
2025-10-17 15:54:01 - [INFO] - Validation Accuracy: 0.7829
2025-10-17 15:54:01 - [INFO] - Validation Macro-F1: 0.7827
2025-10-17 15:54:01 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.7992    0.8775    0.8365       449
   extrinsic     0.8155    0.7093    0.7587       461
   intrinsic     0.7411    0.7653    0.7530       490

    accuracy                         0.7829      1400
   macro avg     0.7853    0.7840    0.7827      1400
weighted avg     0.7842    0.7829    0.7817      1400

2025-10-17 15:54:01 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/infoxlm-large-tuned'...
2025-10-17 15:54:04 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 15:54:04 - [INFO] - --- Epoch 8/10 ---
2025-10-17 15:58:16 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.4371
2025-10-17 15:58:16 - [INFO] - Current Learning Rate: 1.00e-05
2025-10-17 15:58:16 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 15:58:37 - [INFO] - Validation Loss: 0.8011
2025-10-17 15:58:37 - [INFO] - Validation Accuracy: 0.7793
2025-10-17 15:58:37 - [INFO] - Validation Macro-F1: 0.7800
2025-10-17 15:58:37 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.8118    0.8552    0.8330       449
   extrinsic     0.8113    0.7180    0.7618       461
   intrinsic     0.7245    0.7673    0.7453       490

    accuracy                         0.7793      1400
   macro avg     0.7825    0.7802    0.7800      1400
weighted avg     0.7811    0.7793    0.7788      1400

2025-10-17 15:58:37 - [WARNING] - Macro-F1 kh√¥ng c·∫£i thi·ªán. Patience: 1/3
2025-10-17 15:58:37 - [INFO] - --- Epoch 9/10 ---
2025-10-17 16:03:03 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.3873
2025-10-17 16:03:03 - [INFO] - Current Learning Rate: 1.00e-05
2025-10-17 16:03:03 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 16:03:24 - [INFO] - Validation Loss: 0.8801
2025-10-17 16:03:24 - [INFO] - Validation Accuracy: 0.7571
2025-10-17 16:03:24 - [INFO] - Validation Macro-F1: 0.7552
2025-10-17 16:03:24 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.7947    0.8708    0.8310       449
   extrinsic     0.8348    0.6030    0.7003       461
   intrinsic     0.6800    0.7980    0.7343       490

    accuracy                         0.7571      1400
   macro avg     0.7699    0.7573    0.7552      1400
weighted avg     0.7678    0.7571    0.7541      1400

2025-10-17 16:03:24 - [WARNING] - Macro-F1 kh√¥ng c·∫£i thi·ªán. Patience: 2/3
2025-10-17 16:03:24 - [INFO] - --- Epoch 10/10 ---
2025-10-17 16:04:19 - [INFO] - üèÅ Qu√° tr√¨nh hu·∫•n luy·ªán ho√†n t·∫•t.
2025-10-17 16:04:19 - [INFO] - Model t·ªët nh·∫•t v·ªõi Macro-F1 = 0.7827 ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i '/home/guest/Projects/CS221/models/infoxlm-large-tuned'
2025-10-17 16:04:22 - [INFO] - Ph√¢n ph·ªëi k·∫øt qu·∫£ tr√™n t·ª´ng l·ªõp:
  true_label  correct  incorrect  total correct_rate incorrect_rate
0  extrinsic      278        183    461       60.30%         39.70%
1  intrinsic      391         99    490       79.80%         20.20%
2         no      391         58    449       87.08%         12.92%
