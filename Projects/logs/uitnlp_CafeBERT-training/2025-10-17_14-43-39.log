2025-10-17 14:43:39 - [INFO] - Logger cho 'uitnlp_CafeBERT-training' ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o. File log: logs/uitnlp_CafeBERT-training/2025-10-17_14-43-39.log
2025-10-17 14:43:39 - [INFO] - Logger initialized for uitnlp/CafeBERT
2025-10-17 14:43:39 - [INFO] - ============================================================
2025-10-17 14:43:39 - [INFO] - üöÄ STARTING TRAINING SESSION
2025-10-17 14:43:39 - [INFO] - ============================================================
2025-10-17 14:43:39 - [INFO] - ROOT_DIR: /home/guest/Projects/CS221
2025-10-17 14:43:39 - [INFO] - DATA_DIR: /home/guest/Projects/CS221/data
2025-10-17 14:43:39 - [INFO] - TRAIN_FILE: /home/guest/Projects/CS221/data/vihallu-train.csv
2025-10-17 14:43:39 - [INFO] - TEST_FILE: /home/guest/Projects/CS221/data/vihallu-public-test.csv
2025-10-17 14:43:39 - [INFO] - SUBMISSION_DIR: /home/guest/Projects/CS221/submission
2025-10-17 14:43:39 - [INFO] - SUBMISSION_CSV: submit.csv
2025-10-17 14:43:39 - [INFO] - SUBMISSION_ZIP: submit.zip
2025-10-17 14:43:39 - [INFO] - MODEL_NAME: uitnlp/CafeBERT
2025-10-17 14:43:39 - [INFO] - MODEL_OUTPUT_DIR: /home/guest/Projects/CS221/models/CafeBERT-tuned
2025-10-17 14:43:39 - [INFO] - MAX_LENGTH: 512
2025-10-17 14:43:39 - [INFO] - RANDOM_STATE: 42
2025-10-17 14:43:39 - [INFO] - EPOCHS: 10
2025-10-17 14:43:39 - [INFO] - BATCH_SIZE: 4
2025-10-17 14:43:39 - [INFO] - GRADIENT_ACCUMULATION_STEPS: 4
2025-10-17 14:43:39 - [INFO] - SCHEDULER_TYPE: constant_with_warmup
2025-10-17 14:43:39 - [INFO] - LEARNING_RATE: 2e-05
2025-10-17 14:43:39 - [INFO] - WEIGHT_DECAY: 0.01
2025-10-17 14:43:39 - [INFO] - NUM_CYCLES: 3
2025-10-17 14:43:39 - [INFO] - CLASSIFIER_DROPOUT: 0.1
2025-10-17 14:43:39 - [INFO] - LABEL_SMOOTHING: 0.05
2025-10-17 14:43:39 - [INFO] - TOTAL_STEP_SCALE: 0.1
2025-10-17 14:43:39 - [INFO] - EPSILON: 1e-08
2025-10-17 14:43:39 - [INFO] - PATIENCE_LIMIT: 3
2025-10-17 14:43:39 - [INFO] - VALIDATION_SPLIT_SIZE: 0.2
2025-10-17 14:43:39 - [INFO] - LABEL_MAP: {'no': 0, 'extrinsic': 1, 'intrinsic': 2}
2025-10-17 14:43:39 - [INFO] - ID2LABEL: {0: 'no', 1: 'extrinsic', 2: 'intrinsic'}
2025-10-17 14:43:39 - [INFO] - CLASS_WEIGHTS: [1.0393466963622866, 1.0114145354717525, 0.9531590413943355]
2025-10-17 14:43:39 - [INFO] - ============================================================
2025-10-17 14:43:41 - [INFO] - B·∫Øt ƒë·∫ßu pipeline hu·∫•n luy·ªán.
2025-10-17 14:43:41 - [INFO] - B∆∞·ªõc 1: Chu·∫©n b·ªã d·ªØ li·ªáu...
2025-10-17 14:43:42 - [INFO] - Chia d·ªØ li·ªáu: 5600 m·∫´u train, 1400 m·∫´u validation.
2025-10-17 14:43:42 - [INFO] - B∆∞·ªõc 2: T·∫£i model 'uitnlp/CafeBERT' v√† tokenizer...
2025-10-17 14:43:44 - [INFO] - Ph√¢n t√≠ch ki·∫øn tr√∫c m√¥ h√¨nh b·∫±ng torchinfo...
2025-10-17 14:43:48 - [INFO] - Ki·∫øn tr√∫c chi ti·∫øt c·ªßa m√¥ h√¨nh:
=====================================================================================================================================================================
Layer (type:depth-idx)                                            Input Shape               Output Shape              Param #                   Mult-Adds
=====================================================================================================================================================================
XLMRobertaForSequenceClassification                               --                        [4, 3]                    --                        --
‚îú‚îÄXLMRobertaModel: 1-1                                            [4, 512]                  [4, 512, 1024]            --                        --
‚îÇ    ‚îî‚îÄXLMRobertaEmbeddings: 2-1                                  --                        [4, 512, 1024]            --                        --
‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-1                                        [4, 512]                  [4, 512, 1024]            256,002,048               1,024,008,192
‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-2                                        [4, 512]                  [4, 512, 1024]            1,024                     4,096
‚îÇ    ‚îÇ    ‚îî‚îÄEmbedding: 3-3                                        [4, 512]                  [4, 512, 1024]            526,336                   2,105,344
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-4                                        [4, 512, 1024]            [4, 512, 1024]            2,048                     8,192
‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-5                                          [4, 512, 1024]            [4, 512, 1024]            --                        --
‚îÇ    ‚îî‚îÄXLMRobertaEncoder: 2-2                                     [4, 512, 1024]            [4, 512, 1024]            --                        --
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6                                       --                        --                        302,309,376               --
‚îú‚îÄXLMRobertaClassificationHead: 1-2                               [4, 512, 1024]            [4, 3]                    --                        --
‚îÇ    ‚îî‚îÄDropout: 2-3                                               [4, 1024]                 [4, 1024]                 --                        --
‚îÇ    ‚îî‚îÄLinear: 2-4                                                [4, 1024]                 [4, 1024]                 1,049,600                 4,198,400
‚îÇ    ‚îî‚îÄDropout: 2-5                                               [4, 1024]                 [4, 1024]                 --                        --
‚îÇ    ‚îî‚îÄLinear: 2-6                                                [4, 1024]                 [4, 3]                    3,075                     12,300
=====================================================================================================================================================================
Total params: 559,893,507
Trainable params: 559,893,507
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 2.24
=====================================================================================================================================================================
Input size (MB): 0.02
Forward/backward pass size (MB): 4496.33
Params size (MB): 2239.57
Estimated Total Size (MB): 6735.92
=====================================================================================================================================================================
2025-10-17 14:43:48 - [INFO] - B∆∞·ªõc 3: T·∫°o Dataset v√† DataLoader...
2025-10-17 14:43:48 - [INFO] - ‚úÖ T·∫°o DataLoader th√†nh c√¥ng v·ªõi DataCollatorWithPadding chu·∫©n!
2025-10-17 14:43:48 - [INFO] - Gradient accumulation steps: 4 | Effective batch size: 16
2025-10-17 14:43:48 - [INFO] - B∆∞·ªõc 4: Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng hu·∫•n luy·ªán v√† ki·∫øn tr√∫c model...
2025-10-17 14:43:48 - [INFO] - S·ª≠ d·ª•ng thi·∫øt b·ªã: cuda
2025-10-17 14:43:48 - [INFO] - ‚úÖ T√¨m th·∫•y 1 GPU(s).
2025-10-17 14:43:48 - [INFO] - ‚úÖ ƒêang s·ª≠ d·ª•ng GPU: NVIDIA GeForce RTX 5070 Ti
2025-10-17 14:43:48 - [INFO] - Ki·∫øn tr√∫c c·ªßa m√¥ h√¨nh:
XLMRobertaForSequenceClassification(
  (roberta): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 1024, padding_idx=1)
      (position_embeddings): Embedding(514, 1024, padding_idx=1)
      (token_type_embeddings): Embedding(1, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-23): 24 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (classifier): XLMRobertaClassificationHead(
    (dense): Linear(in_features=1024, out_features=1024, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (out_proj): Linear(in_features=1024, out_features=3, bias=True)
  )
)
2025-10-17 14:43:48 - [INFO] - Scheduler will run for 3500 total steps (350 per epoch)
2025-10-17 14:43:48 - [INFO] - S·ª≠ d·ª•ng scheduler chung: constant_with_warmup
2025-10-17 14:43:48 - [INFO] - Warmup steps: 350
2025-10-17 14:43:48 - [INFO] - S·ª≠ d·ª•ng Class Weights & Label smoothing cho h√†m loss.
2025-10-17 14:43:48 - [INFO] - --- Epoch 1/10 ---
2025-10-17 14:48:06 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 1.0178
2025-10-17 14:48:06 - [INFO] - Current Learning Rate: 2.00e-05
2025-10-17 14:48:06 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 14:48:26 - [INFO] - Validation Loss: 0.7258
2025-10-17 14:48:26 - [INFO] - Validation Accuracy: 0.7457
2025-10-17 14:48:26 - [INFO] - Validation Macro-F1: 0.7469
2025-10-17 14:48:26 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.7550    0.8374    0.7941       449
   extrinsic     0.8130    0.7072    0.7564       461
   intrinsic     0.6826    0.6980    0.6902       490

    accuracy                         0.7457      1400
   macro avg     0.7502    0.7475    0.7469      1400
weighted avg     0.7488    0.7457    0.7453      1400

2025-10-17 14:48:26 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/CafeBERT-tuned'...
2025-10-17 14:48:28 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 14:48:28 - [INFO] - --- Epoch 2/10 ---
2025-10-17 14:52:45 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.7031
2025-10-17 14:52:45 - [INFO] - Current Learning Rate: 2.00e-05
2025-10-17 14:52:45 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 14:53:05 - [INFO] - Validation Loss: 0.6790
2025-10-17 14:53:05 - [INFO] - Validation Accuracy: 0.7736
2025-10-17 14:53:05 - [INFO] - Validation Macro-F1: 0.7726
2025-10-17 14:53:05 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.7589    0.8976    0.8224       449
   extrinsic     0.8269    0.6941    0.7547       461
   intrinsic     0.7469    0.7347    0.7407       490

    accuracy                         0.7736      1400
   macro avg     0.7776    0.7755    0.7726      1400
weighted avg     0.7771    0.7736    0.7715      1400

2025-10-17 14:53:05 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/CafeBERT-tuned'...
2025-10-17 14:53:07 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 14:53:07 - [INFO] - --- Epoch 3/10 ---
2025-10-17 14:57:31 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.5761
2025-10-17 14:57:31 - [INFO] - Current Learning Rate: 2.00e-05
2025-10-17 14:57:31 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 14:57:52 - [INFO] - Validation Loss: 0.8530
2025-10-17 14:57:52 - [INFO] - Validation Accuracy: 0.7086
2025-10-17 14:57:52 - [INFO] - Validation Macro-F1: 0.7062
2025-10-17 14:57:52 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.8641    0.5523    0.6739       449
   extrinsic     0.7184    0.7636    0.7403       461
   intrinsic     0.6292    0.8000    0.7044       490

    accuracy                         0.7086      1400
   macro avg     0.7372    0.7053    0.7062      1400
weighted avg     0.7339    0.7086    0.7064      1400

2025-10-17 14:57:52 - [WARNING] - Macro-F1 kh√¥ng c·∫£i thi·ªán. Patience: 1/3
2025-10-17 14:57:52 - [INFO] - --- Epoch 4/10 ---
2025-10-17 15:02:17 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.4816
2025-10-17 15:02:17 - [INFO] - Current Learning Rate: 2.00e-05
2025-10-17 15:02:17 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 15:02:38 - [INFO] - Validation Loss: 0.7248
2025-10-17 15:02:38 - [INFO] - Validation Accuracy: 0.7757
2025-10-17 15:02:38 - [INFO] - Validation Macro-F1: 0.7742
2025-10-17 15:02:38 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.7666    0.8998    0.8279       449
   extrinsic     0.7661    0.7744    0.7702       461
   intrinsic     0.7985    0.6633    0.7246       490

    accuracy                         0.7757      1400
   macro avg     0.7771    0.7791    0.7742      1400
weighted avg     0.7776    0.7757    0.7728      1400

2025-10-17 15:02:38 - [INFO] - üéâ Macro-F1 c·∫£i thi·ªán. ƒêang l∆∞u model t·ªët nh·∫•t v√†o '/home/guest/Projects/CS221/models/CafeBERT-tuned'...
2025-10-17 15:02:40 - [INFO] - L∆∞u model th√†nh c√¥ng.
2025-10-17 15:02:40 - [INFO] - --- Epoch 5/10 ---
2025-10-17 15:07:06 - [INFO] - Loss trung b√¨nh tr√™n t·∫≠p train: 0.4018
2025-10-17 15:07:06 - [INFO] - Current Learning Rate: 2.00e-05
2025-10-17 15:07:06 - [INFO] - B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p validation...
2025-10-17 15:07:26 - [INFO] - Validation Loss: 1.0104
2025-10-17 15:07:26 - [INFO] - Validation Accuracy: 0.7214
2025-10-17 15:07:26 - [INFO] - Validation Macro-F1: 0.7220
2025-10-17 15:07:26 - [INFO] - Classification Report tr√™n t·∫≠p validation:
              precision    recall  f1-score   support

          no     0.8278    0.7817    0.8041       449
   extrinsic     0.8264    0.5575    0.6658       461
   intrinsic     0.6045    0.8204    0.6961       490

    accuracy                         0.7214      1400
   macro avg     0.7529    0.7199    0.7220      1400
weighted avg     0.7492    0.7214    0.7208      1400

2025-10-17 15:07:26 - [WARNING] - Macro-F1 kh√¥ng c·∫£i thi·ªán. Patience: 1/3
2025-10-17 15:07:26 - [INFO] - --- Epoch 6/10 ---
2025-10-17 15:07:32 - [INFO] - üèÅ Qu√° tr√¨nh hu·∫•n luy·ªán ho√†n t·∫•t.
2025-10-17 15:07:32 - [INFO] - Model t·ªët nh·∫•t v·ªõi Macro-F1 = 0.7742 ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i '/home/guest/Projects/CS221/models/CafeBERT-tuned'
2025-10-17 15:07:38 - [INFO] - Ph√¢n ph·ªëi k·∫øt qu·∫£ tr√™n t·ª´ng l·ªõp:
  true_label  correct  incorrect  total correct_rate incorrect_rate
0  extrinsic      257        204    461       55.75%         44.25%
1  intrinsic      402         88    490       82.04%         17.96%
2         no      351         98    449       78.17%         21.83%
